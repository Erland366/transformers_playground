{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "torch.manual_seed(69)\n",
        "torch.set_printoptions(profile=\"short\", sci_mode=False, linewidth=100000)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "# this script is configured to run on a RTX 3060 12GB GPU. you'll want to adjust the model sizes and batch sizes for other devices\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "plt.rcParams['figure.dpi'] = 50\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['xtick.minor.visible'] = True\n",
        "plt.rcParams['ytick.minor.visible'] = True\n",
        "# make 'models' folder to save trained models if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  39526018\n"
          ]
        }
      ],
      "source": [
        "# we use this 40mb file of concatenated anime subtitles as our dataset\n",
        "# just the right size for toy experiments like this I think\n",
        "with open('animesubs.txt', 'r', encoding='latin') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open your mind. Open your mind.\n",
            "\n",
            "Far beyond the deep blue Earth, you and I shall meet...\n",
            "\n",
            "AH! MY GODDESS\n",
            "\n",
            "A snow-white feather comes fluttering down, swaying gently in the air.\n",
            "\n",
            "Without holding back, I want to envelope you, my one and only love.\n",
            "\n",
            "I know I have the power to protect the one I love, right here in my hands.\n",
            "\n",
            "Open your mind. Just as I've always dreamed.\n",
            "\n",
            "Let the wind carry off your hopes, faraway.\n",
            "\n",
            "I have wings nobody can see. Look, you have them, too.\n",
            "\n",
            "They'll take us to where we ca\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 86 \n",
            " !'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|Â”\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '<': 24, '=': 25, '>': 26, '?': 27, '@': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '[': 55, ']': 56, '_': 57, 'a': 58, 'b': 59, 'c': 60, 'd': 61, 'e': 62, 'f': 63, 'g': 64, 'h': 65, 'i': 66, 'j': 67, 'k': 68, 'l': 69, 'm': 70, 'n': 71, 'o': 72, 'p': 73, 'q': 74, 'r': 75, 's': 76, 't': 77, 'u': 78, 'v': 79, 'w': 80, 'x': 81, 'y': 82, 'z': 83, '|': 84, '\\x94': 85, '': 86}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '<', 25: '=', 26: '>', 27: '?', 28: '@', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '|', 85: '\\x94', 86: ''}\n",
            "encoded: [43, 73, 62, 71, 1, 82, 72, 78, 75, 1, 70, 66, 71, 61, 10, 1, 43, 73, 62, 71]\n",
            "decoded: Open your mind. Open\n",
            "vocab size: 87\n"
          ]
        }
      ],
      "source": [
        "# yes, all language models will be character level, which isn't ideal but it's good for simplicity\n",
        "# very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([39526018])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  1, 43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  0,  0, 34, 58, 75,  1, 59, 62, 82, 72, 71, 61,  1, 77, 65, 62,  1, 61, 62, 62, 73,  1, 59, 69, 78, 62,  1, 33, 58, 75, 77, 65,  8,  1, 82, 72, 78,  1, 58, 71, 61,  1, 37,  1, 76, 65, 58, 69, 69,  1, 70, 62, 62, 77, 10, 10, 10,  0,  0, 29, 36,  2,  1, 41, 53,  1, 35, 43, 32])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([39130757]) torch.Size([395261])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.99)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len = 8\n",
        "train_data[:seq_len+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([2, 64])\n",
            "tensor([[64,  1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71],\n",
            "        [62, 70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([2, 64])\n",
            "tensor([[ 1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71, 58],\n",
            "        [70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61, 66]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, seq_len, batch_size=4):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    # targets are just inputs shifted by 1\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - seq_len, (batch_size,))\n",
        "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "xb, yb = get_batch('train', 64, 2)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "327680000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make all steps, sequence lengths, and batch size the same\n",
        "total_steps = 5000\n",
        "seq_len = 256\n",
        "batch_size = 256 # these are small models so we can use large batch sizes to fully utilize the GPU\n",
        "# should cover around 2x the dataset\n",
        "total_steps * seq_len * batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, seq_len, batch_size, total_steps, val_steps=10, val_interval=50):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    # live plot\n",
        "    fig, ax = plt.subplots()\n",
        "    dh = display.display(fig, display_id=True)\n",
        "    for steps in (bar := tqdm(range(total_steps))):  # increase number of steps for good results...\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train', seq_len=seq_len, batch_size=batch_size)\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bar.set_description(f\"loss: {loss.item():.2f}, val loss: {val_losses[-1] if val_losses else 0:.2f}\")\n",
        "        losses.append(loss.item())\n",
        "        if steps % val_interval == 0:\n",
        "            # Calculate validation loss\n",
        "            with torch.no_grad():\n",
        "                val_loss = 0\n",
        "                for _ in range(val_steps):\n",
        "                    xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "                    _, loss = model(xb, yb)\n",
        "                    val_loss += loss.item()\n",
        "                val_loss /= val_steps\n",
        "                val_losses.append(val_loss)\n",
        "            ax.clear()\n",
        "            ax.plot(losses, color='blue', label='train loss', alpha=0.7)\n",
        "            ax.plot(range(0, len(losses), val_interval), val_losses, color='red', label='val loss', alpha=0.7)\n",
        "            ax.set_ylim(0, 4)\n",
        "            ax.legend()\n",
        "            dh.update(fig)\n",
        "    print('final loss:', loss.item(), 'final val loss:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Measure post training perplexity on validation set\n",
        "# Create function that receives a model, context length, and PPL sequence length, and returns the perplexity\n",
        "# The PPL sequence length is the number of characters the function uses to calculate the perplexity\n",
        "# We take the logits and calculate the cross entropy loss from scratch, then exponentiate it to get the perplexity\n",
        "# not only that, but we want the models to do this in actual inference\n",
        "def perplexity(model, seq_len, ppl_seq_len, batch_size=128, val_steps=1000):\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for _ in tqdm(range(val_steps)):\n",
        "            xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                logits, _ = model(xb, yb)\n",
        "            logits = logits.reshape(batch_size, seq_len, vocab_size)\n",
        "            logits = logits[:, :ppl_seq_len]\n",
        "            yb = yb[:, :ppl_seq_len]\n",
        "            # flatten logits and targets\n",
        "            logits = logits.reshape(batch_size*ppl_seq_len, vocab_size)\n",
        "            yb = yb.reshape(batch_size*ppl_seq_len)\n",
        "            # calculate cross entropy loss from scratch\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= val_steps\n",
        "        ppl = torch.exp(torch.tensor(val_loss))\n",
        "        return ppl.item(), val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classic Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, hidden_mult=4):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.hidden_mult = hidden_mult\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "def apply_rotary_emb(\n",
        "    xq: torch.Tensor,\n",
        "    xk: torch.Tensor,\n",
        "    freqs_cis: torch.Tensor,\n",
        "):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    # freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    q_shape = [d if i == xq_.ndim - 2 or i == xq_.ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n",
        "    k_shape = [d if i == xq_.ndim - 2 or i == xk_.ndim - 1 else 1 for i, d in enumerate(xk_.shape)]\n",
        "    T_q = xq_.shape[-2] \n",
        "    q_freqs_cis = freqs_cis[-T_q:].view(*q_shape)\n",
        "    k_freqs_cis = freqs_cis.view(*k_shape)\n",
        "    xq_out = torch.view_as_real(xq_ * q_freqs_cis).flatten(xq.dim() - 1)\n",
        "    xk_out = torch.view_as_real(xk_ * k_freqs_cis).flatten(xq.dim() - 1)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "    \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*config.hidden_mult, bias=False)\n",
        "        self.lin_2 = nn.Linear(config.embed_size, config.embed_size*config.hidden_mult, bias=False)\n",
        "        self.lin_3 = nn.Linear(config.embed_size*config.hidden_mult, config.embed_size, bias=False)\n",
        "        self.silu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lin_1(x)\n",
        "        x2 = self.lin_2(x)\n",
        "        x = self.silu(x1) * x2\n",
        "        x = self.lin_3(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        # block_mask for FlexAttention\n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            causal_mask = q_idx >= kv_idx\n",
        "            return causal_mask\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        _, _, T_past, _ = kv_cache[0].shape if kv_cache is not None and kv_cache[0] is not None else (0, 0, 0, 0)\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x)   # (B, T, C)\n",
        "        v = self.value(x) # (B, T, C)\n",
        "\n",
        "        # Split into heads\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "\n",
        "        if T == self.seq_len: # only in training\n",
        "            out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            # compute attention scores (\"affinities\")\n",
        "            wei = q @ k.transpose(-2,-1) # (B, H, Tq, C/H) @ (B, H, C/H, Tk) -> (B, H, Tq, Tk)\n",
        "            wei = wei * self.head_size ** -0.5 # scaled attention\n",
        "            wei = wei.masked_fill(self.tril[T_k-T:T_k, :T_k] == 0, float('-inf')) # (B, Tq, Tk)\n",
        "            wei = F.softmax(wei, dim=-1) # (B, H, Tq, Tk)\n",
        "            # apply attention to values\n",
        "            out = wei @ v # (B, H, Tq, Tk) @ (B, H, Tk, C/H) -> (B, H, Tq, C/H)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C) # (B, H, Tq, C/H) -> (B, Tq, H, C/H) -> (B, Tq, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "    \n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "    \n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_num = config.layer_num\n",
        "        self.head_num = config.head_num\n",
        "        self.seq_len = config.seq_len\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size, bias=False)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None):\n",
        "        B, T = idx.shape\n",
        "        # print(\"Input shape:\", idx.shape)\n",
        "        # print(\"KV cache shape:\", kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else None)\n",
        "        _, _, T_past, _ = kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else (0, 0, 0, 0)\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = tok_embd\n",
        "        # go through blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i] = cache\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, V = logits.shape\n",
        "            logits = logits.view(B*T, V)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True, use_klcc=False, klcc_cutoff=None, klcc_window_size=None, klcc_steps=None, klcc_lr=1e-5):\n",
        "        if use_cache:\n",
        "            # initialize key-value cache\n",
        "            kv_cache = [(None, None) for _ in range(self.layer_num)]\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            # crop idx to the last seq_len tokens\n",
        "            idx_context = idx[:, -self.seq_len:]\n",
        "            if use_klcc:\n",
        "                all_logits = None\n",
        "            for _ in (bar := tqdm(range(max_new_tokens))):\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context, kv_cache=kv_cache)\n",
        "                if use_klcc:\n",
        "                    all_logits = logits if all_logits is None else torch.cat((all_logits, logits), dim=1)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # do KL context compression\n",
        "                if use_klcc and kv_cache[0][0].shape[2] >= klcc_cutoff:\n",
        "                    self.train()\n",
        "                    klcc_optimizer = torch.optim.AdamW(self.parameters(), lr=klcc_lr)\n",
        "                    for _ in range(1000):\n",
        "                        klcc_logits, _ = self(idx[:, -klcc_window_size:], kv_cache=None)\n",
        "                        labels = \n",
        "                        klcc_loss = F.kl_div(F.log_softmax(klcc_logits, dim=-1), F.softmax(all_logits[:, -klcc_window_size:].detach(), dim=-1), reduction='batchmean')\n",
        "                        # add L1 regularization\n",
        "                        l1_lambda = 1e-7\n",
        "                        l1_norm = sum(p.abs().sum() for p in self.parameters())\n",
        "                        klcc_loss_reg = klcc_loss + l1_lambda * l1_norm\n",
        "                        # print(\"KLCC loss:\", klcc_loss.item())\n",
        "                        bar.set_description(f\"KLCC loss: {klcc_loss.item():.4f}\")\n",
        "                        klcc_optimizer.zero_grad(set_to_none=True)\n",
        "                        klcc_loss_reg.backward()\n",
        "                        klcc_optimizer.step()\n",
        "                        if klcc_loss.item() < 1e-2:\n",
        "                            break\n",
        "                    less_kv_cache = []\n",
        "                    for k, v in kv_cache:\n",
        "                        less_k = k[:, :, -klcc_window_size:, :] if k is not None else None\n",
        "                        less_v = v[:, :, -klcc_window_size:, :] if v is not None else None\n",
        "                        less_kv_cache.append((less_k, less_v))\n",
        "                    kv_cache = less_kv_cache\n",
        "                    self.eval()\n",
        "                    all_logits = None\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "                # since we have kv cache, only need to pass new token\n",
        "                idx_context = idx_next\n",
        "                        \n",
        "            return idx\n",
        "        else:\n",
        "            raise NotImplementedError(\"generate without kv cache is not implemented\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t = tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "index = tensor([[0, 0, 1, 0, 1, 1, 0, 1, 1, 0],\n",
            "        [0, 0, 1, 1, 0, 0, 0, 0, 1, 1]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  1,  0,  1,  1,  0,  1,  1,  0],\n",
              "        [10, 10, 11, 11, 10, 10, 10, 10, 11, 11]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.arange(20).view(2, 10)\n",
        "print(f\"{t = }\")\n",
        "index = (torch.randn(20).view(2, 10) > 0.5).to(torch.int64)\n",
        "print(f\"{index = }\")\n",
        "torch.gather(t, 1, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6339072"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "config = TransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6\n",
        ")\n",
        "m = TransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1)\n",
        "logits, loss = m(xb, yb)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAD+CAYAAABsiV3zAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAHsQAAB7EBBsVhhgAAJq9JREFUeJzt3Xl4VOW9B/Dv7FnIQhICaCAURVmCW0XrUk1RO4ISUVMQYm70ChhZa9oiYGmpD2ChVxQoEisokoqFS1OIonfEW/BWrlsrtzCBohC2EBAmCZN9ssy5f/yYTCbJhGTIkHPG7+d5zjOZM2d535nM7/zO+77njE5RFAVERNRl+p4uABGRVjGAEhEFiAGUiChADKBERAHyG0Crq6tx880347333muet2vXLmRlZSEjIwMlJSWXpYBERGrlN4AuW7YMEyZM8JmXm5uLN998E/Pnz8f69euDXjgiIjUztjdz586dGD58OOrq6nzmK4oCvV6P5ORkFBcXt1nPZrPBZrPh448/xogRI7pUkLIyIw4fNuCWW1xdWk9rXC4XLBZLTxcjqFjH0MA6+qqqqkJ+fr7PvHYD6O7du1FdXY0DBw4gPDwcY8eOhV6vh16vh9vtxokTJ5CUlNRmPavVCqvVipycHKxYsaJLFfnqK+D3vz+HN97o06X1tMZutyMlJaWnixFUrGNoYB195eTktJnXbgBdsmQJAGDDhg1ISEhAVlYW8vLyMG3aNEyZMgUNDQ1YtmzZJRS7LZ2uWzdHRBR07QZQjyeeeAIA8OCDDwIARo8ejdGjRwetMLwmioi0pMMAejkxAyXSFqfTCafTCZ2Gv7wGgwEnT55s9zWdToe4uDhERET4Xb/bA+iXX34Z8LqKot0Pgui7xul0YsCAAZoOoLW1tQgPD2/3taamJpw6dQoDBw70uz4H0hNRQHQ6naaD58UYDIaL1q/bA+ioUaO6e5NE9B2yYcMGnwt4AMDtdrdZLjc3F0eOHOlwW+np6d1attbYBkpEAVMUoKkp8PUNhrbf/U8++QQ1NTUAgK1bt2LQoEEYOXIkamtrsXfvXlRWVmLNmjU4c+YMamtrsWjRIlRWVsJoNGLo0KF48skn2+zntddew759+1BRUYFXXnkFGzZswPHjxxEREYEXXngBWVlZSEpKwh133IHx48d3uvyqCaAAe+GJtKapCXj44cDX/8tfAGOrKHTnnXciISEBDz74ILZu3YqpU6fiyiuvxB//+EeYTCacOnUKe/fu9VlnwoQJuPXWWzFp0qR2A6jNZkN+fj4+/vhjvPPOOzh27BhGjRqF1NRUuFwuVFdXY8yYMbjrrru6VH7VBFCdjgGUSGsMBgmCl7J+a3q9b8tiTEwMAGDLli0oKCjAb37zm+YM1SMyMhKAXC3ZEZ1OB0VRsHLlSnz55Zd4+umnsXnzZuTl5eHDDz/EzJkzkZub2+nyq6oXnoi0Radrm0Fequuvvx5LlixBY2Ojz/z+/ftj+fLl+OKLL3D33Xd3aZv33nsvZs+ejfLycrz88stYvnw5HA4H4uLi4HQ6sXz5chgMhi5fgg6lm33xxRfKs88+2+X1/vlPRcnMPNfdxVGd/fv393QRgo51DA0Xq+OJEycuU0mCp6ampsPXW9axvbimml54diIRkdaoahwo20CJSEtUE0CZgRKR1nR7AGUnEhEFW+sB8sEeMO+PaoYxEZEGBWEkfXZ2NpYsWYLevXtj8uTJWLFiBdasWYPS0lLcf//9HQ509zdgPiYmBgsXLgx4wLw/3R5AR40ahXfeeSegddkGSqQxQRhJP2HCBGzZsgVDhgzB6NGjYTQa4XK50LdvX7z99tsdBj5/A+bHjBlzSQPm/VFNBso2UCINCsJI+tTUVPzhD3/Avn37sHTpUrzxxhtIS0vDrbfeioceeqhTm209YP7JJ5/Epk2bAh4w749qAigRaVAQRtJ7fnetpKQEvXv3xu23347c3Fzs2bMHZrO5w3WDNmDeD9UEULmUk2koEcHnJ4Nuu+023HbbbT6vb926td3n06dP95k/b948n+erV6/uzmKqpxeep/BEpDWqGQcKsBOJiLRFNZdyEpG26HQ6NF3KECaVq6qqgvEi7buqaQMlIm2Ji4vDqVOnNP2zHlVVVejVq1e7rxmNRvTt27fD9VUTQDX8GRB9J0VERHT4g2taYLfbMWDAgIDX93sKf/DgQWRnZyM9PR1r165tnr9o0SJMnDgR2dnZKCkpCXjH7WEbKBFpid8AOmzYMOTm5mLLli3Ys2dP83yj0Qiz2QyTyYTY2NhuKwgzUCLSmg5P4QsKCrB27VpkZmY2z1uwYAH0ej0KCgqwbt06zJ49u/k1m80Gm82GwsJC2O32LhXk9BeluOrEt7Dbh3exCtricDi6/N5oDesYGljHi+swgKalpSEtLQ0PPPAAJk+eDMD7eyWJiYltdmy1WmG1WpGTk4OUlJQuFSTq4BeoKv8MKSkTurSe1tjt9i6/N1rDOoYG1vHi/AbQ3bt3Iz8/Hy6XC2PHjkVmZiby8vKwdOlSnDx5Eg6HA6tWrQp4x60pJjNMble3bY+IKNj8BtDU1FSkpqY2P58xYwYAOYUPCosFBndDcLZNRBQEqrkSSTFbYGpiBkpE2qGaa+EVswVGd303l4aIKHhUk4HCbGYAJSJNUc218HIKzwBKRNqhsgy0gZcjEZFmqCaAKmaL/FHPLJSItEE1AVSn16FRb2QAJSLNUE0vPAA06C2Ai0OZiEgb1JOB6oBGvYkBlIg0QzW98ADQoGMGSkTaoZoMFAAaDGa2gRKRZqgmgMopPDNQItIOVXUiNepNzECJSDNUlYGyF56ItERdnUjshSciDVFNBgqwDZSItEVVAbReb2EbKBFphmoCqPTCm5mBEpFmqKoXvoEZKBFpiMoyUHYiEZF2qKoXvp6XchKRhqgsA2UbKBFph2oCKAA0MIASkYb4DaAHDx5EdnY20tPTsXbt2ub5drsdGRkZyMjIgN1u79bCsBOJiLTEbwAdNmwYcnNzsWXLFuzZs6d5/sqVK7FmzRq8+uqrWL16dbcVRC7lZAZKRNph7OjFgoICrF27FpmZmc3znE4nYmNjAQCVlZU+y9tsNthsNhQWFnY5Oy0qsuDseQMcJSU4082ZrZo4HI5uz9zVhnUMDazjxXUYQNPS0pCWloYHHngAkydPBgDExMTA6XRCp9MhKirKZ3mr1Qqr1YqcnBykpKR0qSDnzgGwOJEQFYWELq6rJXa7vcvvjdawjqGBdbw4vwF09+7dyM/Ph8vlwtixY5GZmYm8vDzMmTMHs2bNAgDMnTs34B23NmAA0KDjOFAi0g6/ATQ1NRWpqanNz2fMmAEASElJwcaNG7u9IP36AW4Tx4ESkXaoZhiTTgfUKeyFJyLtUM218AYDe+GJSFtUlYE26MxQGhoARenp4hARXZRqroXX6yWAQgGzUCLSBFVloNDpoJj508ZEpA2qCaD6CyVRzOyJJyJtUE0nkk534Q8TM1Ai0gbVZKA6nUzMQIlIK1TTieShmDiUiYi0QTUZKCDtoMxAiUgrVBZAFQmgbAMlIg1QVQDV6QA3M1Ai0gjV9MIDFzqReEMRItIIVWWger0CN4cxEZFGqKoXnhkoEWmJqjJQo1FBk4HDmIhIG1QWQIFGAzNQItIGVQVQk8nNnzYmIs1QVS+8yaRIAGUGSkQa0OGvcl5uFosCl2IGGpiBEpH6qaoXPizMjVo3M1Ai0gZVtYGGhSmobWIvPBFpg6oCaESEGzVNzECJSBv8toFu27YNO3bsQEVFBZ566in8+Mc/BgA88cQTMBqNMBqNWLlyJSwWS7cVJiLCjcp69sITkTb4DaDjx4/H+PHjUV5ejp///OfNATQ8PByNjY2IjY2FyWTq1sJERDTBeY4ZKBFpw0V74RcvXowZM2Y0P1+zZg30ej1WrVqF9957D2lpac2v2Ww22Gw2FBYWwm63B1CcBnxzvAFltWdQEtD66udwOAJ8b7SDdQwNrOPF+Q2giqJg3rx5GDNmDG666abm+foLv/6WmJiIqqoqn3WsViusVitycnKQkpLS5cIUFX2Nb/f2QlxkJOICWF8L7HZ7QO+NlrCOoYF1vDi/AXT16tX46KOP4HQ6cfjwYezZswd5eXn42c9+htraWpSXl2PdunUB77g9sbFNOOc0AxaewhOR+vkNoLNnz8bs2bObn2dnZwMAXnrppaAVJjq6Cc46C9xul7qGBxARtUNVccpoBCzRFjTUNgJud08Xh4ioQ6q6Fh4AzlebUFUFDmUiItVTVQYKANDpUOLg1UhEpH6quhYeAMaMAWL7ciwoEamf6jLQ8HCgXscASkTqp7oAGhUF1Cm8nJOI1E91nUjx8UBVIzNQIlI/dWagbv60MRGpn+o6kcLDL5zCMwMlIpVTXQYaEXEhA2UAJSKVU10ANRiA8moLmmoYQIlI3VQXQPv3Bxr0FtQ62QZKROqmul54kwkw9bKgoYoZKBGpm+oyUADQh5tRX8UMlIjUTXW98ABwzmnB6ePMQIlI3VSZgdbrw3D+VE1PF4OIqEOqDKA3WhPRu+FsTxeDiKhDqgyghiv7wXDuTE8Xg4ioQ6rrhQcAY1I/mMq/BRSlG0pERBQcqsxAI/tFwdVkBMrKerooRER+qbIXPqGPDuf0/YAzPI0nIvVSZQYaHw+c1vVnACUiVfMbQLdt24apU6di4sSJ+PDDD5vn79q1C1lZWcjIyEBJSUlQChUVBZQa+sJ5iAGUiNTLbwAdP348Xn/9deTm5mLz5s3N83Nzc/Hmm29i/vz5WL9+fXAKpQfKLf1Qf4IBlIjU66Kn8IsXL8aMGTOanyuKAr1ej+TkZBQXFwetYDHX9oNymgGUiNTL6O8FRVEwb948jBkzBjfddFPzfL1eD7fbjRMnTiApKclnHZvNBpvNhsLCQtjt9i4XxuFwNK/3yeFI3FVxFGcD2I6ataxjqGIdQwPreHF+A+jq1avx0Ucfwel04vDhw9izZw/y8vIwbdo0TJkyBQ0NDVi2bJnPOlarFVarFTk5OUhJSelyYex2e/N6jXGNaDxaj+9ffTUQFtblbalVyzqGKtYxNLCOF+c3gM6ePRuzZ89ufp6dnQ0AGD16NEaPHh3wDjvLrTeiwpwAfPstkJwc9P0REXWVKocxAYBOB5RbOJSJiNRLlZdyAsDkycB5S192JBGRaqk2A504ETgfxqFMRKReqryUE5BT+DJzP5znYHoiUinVZqCADKYv/pIBlIjUSfUBtJ+et7UjInVSdQCtNUbhRIkJKC3t6aIQEbWh2l54AIBOh3MG3taOiNRJ1RnoNdcA5WH9gNOne7ooRERtqLYXHgAyM4GSyGvQtP9At22TiKi7qDoDHToUOBJ9I3a/vJcdSUSkOqoOoGFhwLcR34NeaQROnuzp4hAR+VB1AAUA6HQoir4R2Lu3p0tCRORD3b3wAL73PeBIzE2o/5wBlIjURfUZaFwccDT6epyy2YH6+p4uDhFRM1X3wgPA008DVeY41MT0Bw6wN56I1EP1GWj//vL4USnbQYlIXVQfQD2OxNwE99+/6uliEBE100QAnT4dOBk1HE3FJUBZWU8Xh4gIgAZ64QHg+98HGvVmfB19M/Dhh92+fSKiQGgiA01MlMeXSiYD27YBFRU9Wh4iIkADvfAtnYtIxpE+twL/+Z9B2wcRUWdpIgMFgMcfl8dfH8oAbDbg3LmeLRARfef5DaBFRUV46qmnkJ6e7jN/0aJFmDhxIrKzs1FSUhL0AnpMmCCPTksicO+9wDvvXLZ9ExG1x28AHTx4MNavX99mvtFohNlshslkQmxsbDDL5kOn8/69K3Ei8Omn7FAioh7V5VP4BQsWIC8vD/fddx/WrVsXjDL5tWGDPK5YHwNl8RJg82ZgzRqgoeGyloOICACMXV1Br5eYm5iYCLvd7vOazWaDzWZDYWFhm9c6w+FwXHS9ysqBAIDs5b0wZ9o0JLz5JnTTpuHs9OlQwsO7vM/LrTN11DrWMTSwjp2g+OFwOJSnn35aGTx4sLJ06VLl8ccfVxRFUZYsWaJkZ2cr6enpSklJSbvrPvvss/4226H9+/dfdJn8fEV58EGZSkoURWlqUpTlyxXll79UlIaGgPZ7OXWmjlrHOoYG1tFXe3HNbwYaHx+P3NzcNvMXLFgQeLTuBg8/DLzxhvw9bRrw7rt64Kc/BRYtAlavlr9bNpgSEQWJZoYxtfTb33r/rq4GYDIBCxYAR44A69cDjY09VjYi+u7QxKWcrY0Y4f37sceAQ4cAREYCv/kN8PXXwLPPAv/6V9DLQUTfbZrMQAHg7be9f//85xcy0fh4YNky4MEHgRdekOmtt4CdO4HS0h4rKxGFJk1dytlSdDRw113e5489BuzaBWn/tFqBtWuBO+6Q559/DsyaJQvw1z2JqJt0eRiTmvziFxIrn39enq9YIfcaeeUVQBcTA9xzj3fhgweBl1+WAfjp6cDgwYBR09Unoh6m+Qhy3XW+z4uKgLQ04C9/AfR6mQAAw4YBq1YBf/wj8LvfyX1Fr7oKuPpqeRwyBBg48LKXn4i0S7NtoC0VFAB33uk77+GHgYceAsrLW8wMCwOmTAFef1166x99FIiKkqx0/nzg17+Wnnwiok7o9gz0cvTCt6bTAc89J9O4cb6v/du/Ae++285KsbHArbfKBAAuF/Dee8DChfJbyhaLDIcyGoE+fYC+fWV+SooMmyKi7zzNn8K39tZbQFaW77xx44AbbwR+9asOmj0tFslI778f+PvfJSobjRJEz54FTp8Gdu+WxxtvBK69FujXT+727HbLTZ5ra4Hhw4GEhGBXk4hUoNsD6KhRo/BOD95qLi4O+NOfpFe+pb175bQeAB55BLj7bjl7j41tlVBGRsqL/jgcwJdfAkePAv/8pwRXg0GGBZjNcjVUcjLwgx9IxjpwoARUXh1FFHJCLgMFJAb++c8Sz1qf0gNAfr5MHs8917YN1a+EBGDMGP+vu1zAV19JFvvZZ8DJk0B9vWS4ZjP619dLz1dSkmS45eUyKQoQHi5TdLRE9pgYeR4WJusbjTJFRsqRgkGZqEeFZAAFJHgCMrQpJkY633ftan/ZZctkAoC8PFk+4NhksQC33SYTIIGxqkqCaH09yr78EvEREcCpU3LKf8UVcmmVTifPa2ulOaCoCHA65XldnUxNTdKkUFkp2x4wQIKtyyW39IuIkLbavn0lwEZHS5qt10s5DAZpcujVy1tBRZFJHxL9iUSXVcgGUI8hQ+QxJ0eu8Pz0U+DFF/0vn5kpj9deC0ydKjFr2DBg/Hhg+XKZ3yU6nQSxC1yDB0tH1KVQFBmGdfKkBOcL2S2qqoAzZ2T6+msJxJWV3osHGhvlp1AsFslwq6pkGZNJmhuuukqCbm0tUFMjl3dVV8vzXr3kSq/evWV5nU4mt1um8HB5s6++WvZTVCTNHOHhcoCIiWm/Hi6XZNitVVfL1WOlpRL4+/WT7J+BnlQkJHrhO0unA26/XXrlGxuB99+XEU3tOXRILhFtacUK+W0mgwG4+WZvlnvZ6XQSzOLju76u2y3tuE6nBPboaMmOjxyRqapK5vftKxltZKQEuKoqCWbnz0twUxTZlmewrcMB/PWvQHExBlZUAIMGSVCurgZeeklGMsTEyLJutzRbOBzyQVxxBTBypATJw4floofz5yVYx8fLUez0aQm2cXEy9e4t2/Fk5w0Nsi2dTl5PSJDHqCgJ/oAcLJxO+QDj4uQgUlkJlJTI9p1OWcblkjINHChlMhql3GazrBMdDdOpU7Kd2lqZHxXlfT9b9lT6y/AVRfZXUyNTWJicHZjN3gNkWZm8jy0b6YuKpHkoOlreg9695X2NiZEDY1OTvC+egxwFVchnoP4YjTLgPi1NErk+feR7NGeO/3VKSiQLbU9WlnTiOxzeTnhV/v/q9fJF9fxWNCCB8vvfl+lS1dWheN8+DL/lFu+8hgYJzp7Aq9PJF79PHwkc33wD2O3yBl9/PTBxogSv1kGnqkre4LIyCcAGg7eN2NM+rCgS6D3LnTgh6ymKBJnoaAkyhw5JkI6KkmD5gx80B0eYzVKWEyeA48e9QcnlkqDndKLPuXOyXliY1K+y0ht8PYHU0xzT1CTNLVdfLfMPH5apqUmCe3i4LFte7l1Pr5fy1tQAP/yhnLXs3Cnr3XGHlMvTfu50euvoYTDI+p4g6wm0dXVS1ro6CbJhYbJ/T5t7fb1s+/hx9D950nsAsVhk2bAw78GiVy85aDU0yPYqKmSqrpb5jY1SD0/bvqJI3errgf79gWuukSsCa2vls3I4pGnL07w1ZIgsEx/vfX/DwqT/4MorZb+lpbKuokg5TSb5AiYmyv+1wyFnZNXVUr/YWNleN918PeR64QMxYIA8Dh4sVzC9/75Mp051fhtvvSVTazEx8v/9059K537I32kvLAzuiAjfeSYTMHSo/3WGD5fpYnr1kmnQoEsqYqckJ3vbsdtRYrcjrr2mGJdLglpFhXyBo6MlmB09KgeRigq52Y0nMLQ8ytbXS0CIjJQApdPJ0f2vfwW2b5d/oAUL2m/ycLu9AUuv9wbkllNFhWTeycnewO9ySZB2OiVwGgzNdS8tKUH8974n23W5JEjW1nqbfsrKvEHLYpH1YmKk/CaTvOZ2e5uE9HrZr8kEFBfLHdP+67/kffKcUQ0fDtx3n/fA6jnQRUfLVFMDfPyxfDnNZm+zkl4vBySXS97Ds2elftHREqwjIpoPfrjnHm9b3SX6zmag/rTMTD3cbhkCWl0tn/v773d+e06nPL7yikyVlQNbNon6eOYZOUCOGCH/A4MH+75eViYZcMv7oZLKWCyStfXr5zs/JeXibd9ms3zZWxowoO3A5vZ4mhg8IiNlSkrqXLnbUW+xXHp7vT833XTxZa69Vg42gVAU7+iXIGIA7QS9Hhg92vv8Jz+RM4Djx+VA2KePHJC/+UaSjP37A9vP2rX+X+vfXw7EtbUyNGvTJpm/fbvclSomRvZ9zTXeJr/O2LRJzl5bB2siTdPpgh48AQbQgHjaOFufeXpur6coQGGhHACTkuQmUBYL8I9/BL7P06d9n0+e7P1782b/6xkMcmYDSCfYwoXSdPfNNzK06513JKueO1eai0wmSWQ8zXOAtzmr9ZljTY0cSFTZ1kt0GXyneuEvF53O98yn5bApu/0ERoxIaV7u3DlpwjEYgHXr5MYo3ckTPAEZygVI8ARkRAEA/O1vMnVWQoIEW0AODC4XMGqU9Lv8x38A27fHYv58aU82GqVT/dw5aY76/e+BV1+V5ojw8PZHNxFpBTPQHtAyY+vTx/v31KkyuVySxTY0SPNBRISMX21slI5ys1lO5+vq5F7R334rbfGXiyd4AlJWQK5uBYBJk4DKymhERXkvnW3t0Uc7t59Zs6SeV10lF0F8/LHcYWvMGLmSLCpKrjjLzJT7wgLegHzsmPQ1ud3SD3PllRLM6+qkP6V1UyNRINgLr0KeppuWp8y33+67jCfwekYQzJghj263dJLa7cAttwDTp8vp+cmTMizzz3+WDrF//3e50rS+XkbGPPSQtKeqyerVbedt3962nHl5MnXVzTfLkMqWoqK8F3pdd520KyclSadeerrc/uDRR4HCwjD89rdy1nD8uATopiaZduzwHjy+/VaG1HqaQ775RoJ3y3bqxkYZMdWyHbqhwXs/G8A77NZg6Ho9KXiYgYYYvV5OlT0B9w9/kMerr5bHn/1Mgm1YWNsMccoU+TJXVcloAA/PBUMWS9v2TkWR7Dg5WUbbbNkCPPJIOcaMicbmzRIYWrffqkXr4Al4gycA7Nsnj4cOyaPnV74//RSorExEVJR0KLZny5buK6c/d94JfPGFlCE+Hvjv/5bP/bPPpJM7LEyaSkwmuYFYfb03Ix89Wua73cCePdL8kpkpAf6qq6RT9OxZI06dkmGUI0ZIMHc45CDzv/8rB+/Bg71j/2tqpOPfM9S3teJiOdB4XvOcYV3soOB2y4Gos2cNNTVy1nY5+A2gRUVFWLJkCZxOJ7Zu3do8326348ULjXrz589HSrCGOVDQtDeM0MNo9A2egPzD+1vHc3UXIKfvP/kJcPhwJYYMAX75S99lPeO8/XU6/d//yb7LyyUgGwzyZdDp5As7frwE+dRUGVJWUSEdYtdcAyxeLNn1pEkSKCIjL/zQYAj75BN5bPkDi4WF8th6JIhn1IaH58DaUuugX1l5hd8hd13lGQ/tMXu2/ECEx7BhcuBOTZVsX6+XdvXYWDlg/elPEuB79ZIrCaurZXTXkSNycVbfvnK9wXXXyXUYgDwOHSoH/qFD5czg7rtlG911S1+donT8K2vp6ek+AXTq1Kn43e9+B51Oh7lz5+K1115rs05OTg5WrFjR5cLY7faQD8is4+VXXe0dXeBRVyejIu64wztPUaSzq08fCdplZZIlHTsmbc9790rzwYIFwHvvHQZwNTZtAjZulGC/Y4dcQLV5swTwIUMkE1ywQLY/bJh0qGlFZWUFoqKie7oYQeG5yXpX/lfbi2tdPoV3Op2IvZCiVLY83wFgs9lgs9lQWFgIu93e1U3D4XAEtJ6WsI7qERMjbcWtnT3r+zwyUi6aCQ+X+8wWFQGJiQ4kJNRh8WJppgC8Q9qeesp3/RdfbP+09sCBMFxzTZ3fm3zLlY86GAxAebkRLpcOSUn1+Ne/wjBiRF3zMi2329gInD9vQFOTDvv3R2Dbtlj86EeVqKnRY8SIWgwdWguXS4/SUiN27IjFN99YMHPmWbz1VgIqK/W47rpa3HefEy+91A9ZWYfw1VcDsX+/XPZ47bV1OHQoDLfeWo2zZ404etT/OEuTSUFDg3rHt9nt8qFd6v9qlwNoTEwMnE4ndDodolrl91arFVarFTk5OQFlIGrLXIKBdQwN3VHHQFe//vrOLXfPPXIJMdB+Fjl+vOevaKSne/8G+mLcOMBuD8eTT/ZtsUZ0q0fhuS9N61sXnDsnbbN6vRyULBbfYWueX8ypqZF2TkCueB00yPtjEJ4QU1Ymw/0A7z1hBg703k9m+3Y5kAwdKqfocXHS7LRnj+z3738HDhwA7r3X88s88uZf6ufoN4CWlpbi+eefx969e/Hiiy/iwIEDyMvLw5w5czBr1iwAwNy5cwPeMRGFBn9jeVsO0Wt57xoPT+bdssNn5Mj2txUX57s/zz49w/wmTWp/vfvuk0fPRS7dzW8AjY+PR66n27GFlJQUbNy4MTilISLSEN6dlogoQN0eQHkpJxF9VzADJSIKULcH0FGjRnX3JomIVIkZKBFRgBhAiYgCxABKRBQg9sITEQWIGSgRUYDYC09EFCBmoEREAWIAJSIKEAMoEVGA2AtPRBQgZqBERAFiLzwRUYCYgRIRBYgBlIgoQOxEIiIKEDNQIqIAsROJiChAzECJiALEAEpEFCC/vwtfXV2N6dOnw2w2IzU1FRkZGQCARYsW4eDBg+jduzd+9atf4YorrrhshSUiUhO/GWh+fj7S09Px+uuvo6CgoHm+0WiE2WyGyWRCbGzs5SgjEZEq+c1Ai4uLMXLkSACAwWBonr9gwQLo9XoUFBRg3bp1mD17dvNrNpsNNpsNhYWFsNvtXS6Mw+EIaD0tYR1DA+sYGi61jn4DaFJSEoqLi3HDDTfA7XY3z9frJWlNTExss2Or1Qqr1YqcnBykpKR0uTB2uz2g9bSEdQwNrGNouNQ6+g2gjzzyCGbOnIkdO3Zg3LhxyMzMRF5eHpYuXYqTJ0/C4XBg1apVAe+YiEjr/AbQyMhIvPnmm83PPZ1ICxYsCH6piIg0gMOYiIgCxGvhiYgCxAyUiChAvBaeiChAzECJiALEAEpEFCAGUCKiALEXnogoQMxAiYgCxF54IqIAMQMlIgoQAygRUYAYQImIAsReeCKiADEDJSIKEHvhiYgCxAyUiChADKBERAFiJxIRUYCYgRIRBYidSEREAWIGSkQUIAZQIqIA+Q2g1dXVyMrKwtSpU/H22283z7fb7cjIyEBGRgbsdvtlKSQRkRr5DaD5+flIT0/H66+/joKCgub5K1euxJo1a/Dqq69i9erVl6WQRERqZPT3QnFxMUaOHAkAMBgMzfOdTidiY2MBAJWVlT7r2Gw22Gw2fP7558jJycGZM2cAAP369etUYY4dO4ZBgwZ1atmubDtYywayPOt4ecrBOl768lqrY1fLAXTt+3js2LG2MxU/Nm7cqLz77ruKoijKxIkTm+dPmTJFOX/+vOJ0OpVp06b5Wz0gzz77bLduT41Yx9DAOoaGS62j3wz0kUcewcyZM7Fjxw6MGzcOmZmZyMvLw5w5czBr1iwAwNy5czsd6TvDarV26/bUiHUMDaxjaLjUOuoURVG6qSxERN8pHMZERBQgv6fwl1N1dTWmT58Os9mM1NRUZGRk9HSRAlZUVIQlS5bA6XRi69at2LRpE3bt2gWXy4W1a9cCQJu6tl4mMjKyh2vRsW3btmHHjh2oqKjAU089hf379+Po0aNoaGhAbm4uTp8+jV/84hcwGAx48skn8aMf/QgvvfSSzzI6na6nq9GhgwcPYuXKlXA4HLjnnnsQExMTcp9jdXU17r77bixatAiHDh0Kuc9w9+7dWLhwIUaMGIHHHnsM//jHP7q/jt3SEnuJNm7cqBQUFCiKoigTJkzo4dJ0j0cffVRRFEVJT09XFEVR3n33XWXjxo3t1rX1MlpRVlamPPHEE8rkyZMVRVGU1atXK//zP/+jvPDCC8q+ffuUpqYmZdKkSYrL5WqzjFY0NTUpGRkZIfk5Lly4UFm2bJmyffv2kPwMd+/erdx///1KVlaWcujQoaDUURWn8MXFxRgwYAAA3yFTocBzBEtOTkZxcXG7dW29jFYsXrwYU6ZMQZ8+fQC0raNeL/9epaWlbZbRgoKCAjzwwAMYO3ZsyH2OO3fuxPDhw5GYmAin0xmSn+EPf/hDfPDBB1i2bBmeeeaZoNRRFQE0KSmpubBut7uHSxMcJ06cQFJSUod19Syjdoqi4LnnnsOYMWMwatQoOBwOAG3r6KlffHx8m2W0IC0tDR988IHPlXih8jnu3r0bn332GTZt2oRNmzbh7NmzAELrM/QExt69eyMmJiYo/6eq6IWvrq7GzJkzERYWhjvvvFPTbaClpaV4/vnnsXPnTkyZMgXJycn429/+htraWqxZswYA2tR106ZNPsuove1s1apVeOuttzBq1CjccMMNqKmpwfHjx5vb/k6fPo158+bBaDTi8ccfx+jRo7FixQqfZbTQfpafnw+Xy4XrrrsOvXv3DrnPEQA2bNiAhIQEfP311yH3Gebn58Nms+H8+fN45pln8NVXX3V7HVURQImItEgVp/BERFrEAEpEFCAGUCKiADGAEhEFiAGUiChA/w/4gkC+TVE88wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ce0d6865da8428daa9ecf9a046c4149",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.venv/lib/python3.11/site-packages/torch/_inductor/lowering.py:1917: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final loss: 1.00412118434906 final val loss: 1.1727005958557128\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "# torch.save(model.state_dict(), 'models/TransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): TransformerLM(\n",
              "    (token_embedding_table): Embedding(87, 256)\n",
              "    (lm_head): Linear(in_features=256, out_features=87, bias=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-5): 6 x Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=False)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=False)\n",
              "          (lin_2): Linear(in_features=256, out_features=1024, bias=False)\n",
              "          (lin_3): Linear(in_features=1024, out_features=256, bias=False)\n",
              "          (silu): SiLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/TransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # calculate perplexity\n",
        "# ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "# print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# idx = encode(\"You will never\")\n",
        "# print(torch.tensor([idx]))\n",
        "# print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c7a3ffec69b4d49b0efdcb08fdbc039",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You will never forget the form of a Corpse and the Crown Prince\n",
            "\n",
            "are also an abbrasive person.\n",
            "\n",
            "Oh, I'll be running away for a while now.\n",
            "\n",
            "Thanks for the letter that I was the one before.\n",
            "\n",
            "You should learn to take the prince should be the best growth.\n",
            "\n",
            "I'll be say thanks to you as a mercharch and to go to a fan would be great as a totally like to the town and thank getting in the care between the last than a long onle leave because of the breesalive.\n",
            "\n",
            "Oh sale become from the becon and see happened of man tound is an distrately afrea\n",
            "\n",
            "because the topens toman faster for and greate the sat sedish\n",
            "\n",
            "Ever seat betere because tone is the situnes the migraside the toppone\n",
            "\n",
            "with the shace as the wastete the the bester trear\n",
            "\n",
            "the patreal betweeere\n",
            "\n",
            "that at tone fall here\n",
            "\n",
            "also toweed the last for the lotel\n",
            "\n",
            "of the seat the lately to becated ehe chers it thre theire the fine.\n",
            "\n",
            "If the mature towe the sale be\n",
            "\n",
            "bethe en for the laste the becan the foune lese\n",
            "\n",
            "the late the gonnice\n",
            "\n",
            "and the leased towe than the preste athe we\n",
            "\n",
            "the a lel\n",
            "\n",
            "the ceasie the land the che frese begires alive tha\n",
            "\n",
            "ashe leave falefunasto the se.\n",
            "\n",
            "In so sear recre if to the ale fe line the secear\n",
            "\n",
            ".\n",
            "\n",
            "gre the preceise hen beside the se toor satiser the ens the than\n",
            "\n",
            "Thi mathe de so bue se\n",
            "\n",
            "the tothe che\n",
            "\n",
            " the sand gene be ta fits catte the fraste\n",
            "\n",
            "\n",
            "\n",
            "the ceare the re the rece\n",
            "\n",
            "mand\n",
            "\n",
            "\n",
            "ne the\n",
            "\n",
            "the\n",
            "\n",
            "\n",
            " fat be the than the rether\n",
            "\n",
            " gre\n",
            "\n",
            "\n",
            "and the the lethe fecelsoune.\n",
            "\n",
            "\n",
            "Be\n",
            "\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "Fasthan the the sate is\n",
            "\n",
            "\n",
            "\n",
            ".whe we\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "d the he fe\n",
            "\n",
            "\n",
            "E whasere the rere\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Seshe giese.\n",
            "\n",
            "\n",
            "the lound\n",
            "\n",
            "\n",
            "the Le gar the me sthe the ile.\n",
            "\n",
            "\n",
            "Sere behe sthan the che sthe isthe tod the seatre cow\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " lithe beie de gre conerud\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the cafo re ta reeli\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "le belifend belhe hathe the re sancere\n",
            "\n",
            "\n",
            "\n",
            "fentherou perede\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " fir gue\n",
            "\n",
            "\n",
            "\n",
            ". the cere\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " the he letothe the re\n",
            "\n",
            "\n",
            "\n",
            " the saf beasellind belie\n",
            "\n",
            "\n",
            " se sirese\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " that ne sato the\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " depenele gie.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "thate\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "So the be\n",
            "\n",
            "\n",
            " reatere sashe the topence\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " the the and\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tshe the tothe the the the the did\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " be\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " the ge\n",
            "\n",
            "\n",
            "\n",
            "brethe ceastore the be bece\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tha we\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".re\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " be\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ashista se fo bethe fithe therathe mel lasthe cothe comgiles\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "and kre paseigre\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " she bef\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "be fou\n",
            "\n",
            " bi\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " she go\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " sthe thre be the itwelfre tothe ce ligire\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The surim\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " gha\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "S\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "thas\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " lithe\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " sthaw lre hal\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "thel\n",
            "\n",
            "\n",
            "sstha Zgu\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "S\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "thel bre\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "W\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "f\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ale\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ll\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the thele f \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bele\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tt\n",
            "c athastw\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ls\n",
            "tala\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "be\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "caf sthe llie\n",
            "Are\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the ber\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Se\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ta\n",
            "\n",
            "\n",
            "Thal\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=3000, temperature=0.5, use_cache=True, use_klcc=True, klcc_cutoff=64, klcc_window_size=32, klcc_steps=5, klcc_lr=1e-4)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
