{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from einops import rearrange, repeat, reduce\n",
        "# import lovely_tensors as lt; lt.monkey_patch() # INTRODUCE GRAPH BREAK!\n",
        "\n",
        "torch.manual_seed(69)\n",
        "torch.set_printoptions(profile=\"short\", sci_mode=False, linewidth=100000)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "# this script is configured to run on a RTX 3060 12GB GPU. you'll want to adjust the model sizes and batch sizes for other devices\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "plt.rcParams['figure.dpi'] = 50\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['xtick.minor.visible'] = True\n",
        "plt.rcParams['ytick.minor.visible'] = True\n",
        "\n",
        "USE_SDPA = False\n",
        "USE_TORCH_COMPILE = False\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  39526018\n"
          ]
        }
      ],
      "source": [
        "# we use this 40mb file of concatenated anime subtitles as our dataset\n",
        "# just the right size for toy experiments like this I think\n",
        "with open('animesubs.txt', 'r', encoding='latin') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open your mind. Open your mind.\n",
            "\n",
            "Far beyond the deep blue Earth, you and I shall meet...\n",
            "\n",
            "AH! MY GODDESS\n",
            "\n",
            "A snow-white feather comes fluttering down, swaying gently in the air.\n",
            "\n",
            "Without holding back, I want to envelope you, my one and only love.\n",
            "\n",
            "I know I have the power to protect the one I love, right here in my hands.\n",
            "\n",
            "Open your mind. Just as I've always dreamed.\n",
            "\n",
            "Let the wind carry off your hopes, faraway.\n",
            "\n",
            "I have wings nobody can see. Look, you have them, too.\n",
            "\n",
            "They'll take us to where we ca\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 86 \n",
            " !'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|Â”\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '<': 24, '=': 25, '>': 26, '?': 27, '@': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '[': 55, ']': 56, '_': 57, 'a': 58, 'b': 59, 'c': 60, 'd': 61, 'e': 62, 'f': 63, 'g': 64, 'h': 65, 'i': 66, 'j': 67, 'k': 68, 'l': 69, 'm': 70, 'n': 71, 'o': 72, 'p': 73, 'q': 74, 'r': 75, 's': 76, 't': 77, 'u': 78, 'v': 79, 'w': 80, 'x': 81, 'y': 82, 'z': 83, '|': 84, '\\x94': 85, '': 86}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '<', 25: '=', 26: '>', 27: '?', 28: '@', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '|', 85: '\\x94', 86: ''}\n",
            "encoded: [43, 73, 62, 71, 1, 82, 72, 78, 75, 1, 70, 66, 71, 61, 10, 1, 43, 73, 62, 71]\n",
            "decoded: Open your mind. Open\n",
            "vocab size: 87\n"
          ]
        }
      ],
      "source": [
        "# yes, all language models will be character level, which isn't ideal but it's good for simplicity\n",
        "# very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([39526018])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  1, 43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  0,  0, 34, 58, 75,  1, 59, 62, 82, 72, 71, 61,  1, 77, 65, 62,  1, 61, 62, 62, 73,  1, 59, 69, 78, 62,  1, 33, 58, 75, 77, 65,  8,  1, 82, 72, 78,  1, 58, 71, 61,  1, 37,  1, 76, 65, 58, 69, 69,  1, 70, 62, 62, 77, 10, 10, 10,  0,  0, 29, 36,  2,  1, 41, 53,  1, 35, 43, 32])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([39130757]) torch.Size([395261])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.99)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len = 8\n",
        "train_data[:seq_len+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([2, 3, 64])\n",
            "tensor([[[62, 71, 77,  1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80],\n",
            "         [71, 77,  1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80, 65],\n",
            "         [77,  1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80, 65, 72]],\n",
            "\n",
            "        [[58, 75, 62,  1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1],\n",
            "         [75, 62,  1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1, 65],\n",
            "         [62,  1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1, 65, 66]]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([2, 3, 64])\n",
            "tensor([[[71, 77,  1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80, 65],\n",
            "         [77,  1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80, 65, 72],\n",
            "         [ 1, 59, 58, 60, 68,  1, 80, 66, 77, 65,  1, 65, 66, 76,  1, 70, 72, 70,  1, 77, 72,  1, 65, 66, 76,  1, 73, 58, 75, 62, 71, 77, 76,  3,  1, 65, 72, 78, 76, 62, 10,  0,  0, 29, 76,  1, 63, 72, 75,  1, 48, 72, 61, 72, 75, 72, 68, 66,  8,  1, 80, 65, 72,  1]],\n",
            "\n",
            "        [[75, 62,  1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1, 65],\n",
            "         [62,  1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1, 65, 66],\n",
            "         [ 1, 66, 71, 79, 78, 69, 71, 62, 75, 58, 59, 69, 62,  2,  0,  0, 51, 65, 62, 75, 62,  1, 61, 66, 61,  1, 77, 65, 62, 82,  1, 61, 66, 76, 58, 73, 73, 62, 58, 75,  1, 77, 72,  2, 27,  0,  0, 40, 62, 77,  3, 76,  1, 64, 72,  1, 76, 58, 79, 62,  1, 65, 66, 70]]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, seq_len, batch_size=4, n_future_tokens=1):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    max_start_index = len(data) - seq_len - n_future_tokens\n",
        "    ix = torch.randint(max_start_index, (batch_size,))\n",
        "    # --- Vectorized Indexing ---\n",
        "    # Instead of looping, we compute all indices at once.\n",
        "\n",
        "    # 1. Create indices for the input sequences `x`.\n",
        "    # `t_range` creates the offsets for each token in a sequence [0, 1, ..., seq_len-1]\n",
        "    t_range = torch.arange(seq_len)\n",
        "    # Use broadcasting to create a grid of indices for the entire batch.\n",
        "    # `ix.unsqueeze(1)` has shape (batch_size, 1)\n",
        "    # `t_range` has shape (seq_len)\n",
        "    # The result `x_indices` has shape (batch_size, seq_len)\n",
        "    x_indices = ix.unsqueeze(1) + t_range\n",
        "\n",
        "    # 2. Create indices for the target sequences `y`.\n",
        "    # `f_range` creates offsets for the future tokens [0, 1, ..., n_future_tokens-1]\n",
        "    f_range = torch.arange(n_future_tokens)\n",
        "    # We build upon `x_indices` to get the target indices.\n",
        "    # `x_indices.unsqueeze(2)` has shape (batch_size, seq_len, 1)\n",
        "    # `f_range` has shape (n_future_tokens)\n",
        "    # Broadcasting creates `y_indices` with shape (batch_size, seq_len, n_future_tokens)\n",
        "    # Each y_indices[b, t, :] corresponds to the targets for input x[b, t].\n",
        "    y_indices = x_indices.unsqueeze(2) + f_range + 1\n",
        "\n",
        "    x = data[x_indices]\n",
        "    y = data[y_indices]\n",
        "    y = y.transpose(1, 2)\n",
        "\n",
        "    if n_future_tokens == 1:\n",
        "        y = y.squeeze(1)\n",
        "\n",
        "    x = x.unsqueeze(1)\n",
        "    # print(f\"{x.shape = }, {y.shape = }\")\n",
        "    x = torch.concat([x, y], dim=1)\n",
        "    x = x[:, :-1, :]\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "xb, yb = get_batch('train', 64, 2, 3)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "327680000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make all steps, sequence lengths, and batch size the same\n",
        "total_steps = 5000\n",
        "seq_len = 256\n",
        "batch_size = 256 # these are small models so we can use large batch sizes to fully utilize the GPU\n",
        "# should cover around 2x the dataset\n",
        "total_steps * seq_len * batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, seq_len, batch_size, total_steps, val_steps=10, val_interval=50, n_future_tokens=1):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    # live plot\n",
        "    fig, ax = plt.subplots()\n",
        "    dh = display.display(fig, display_id=True)\n",
        "    for steps in (bar := tqdm(range(total_steps))):  # increase number of steps for good results...\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train', seq_len=seq_len, batch_size=batch_size, n_future_tokens=n_future_tokens)\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bar.set_description(f\"loss: {loss.item():.2f}, val loss: {val_losses[-1] if val_losses else 0:.2f}\")\n",
        "        losses.append(loss.item())\n",
        "        if steps % val_interval == 0:\n",
        "            # Calculate validation loss\n",
        "            with torch.no_grad():\n",
        "                val_loss = 0\n",
        "                for _ in range(val_steps):\n",
        "                    xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size, n_future_tokens=n_future_tokens)\n",
        "                    _, loss = model(xb, yb)\n",
        "                    val_loss += loss.item()\n",
        "                val_loss /= val_steps\n",
        "                val_losses.append(val_loss)\n",
        "            ax.clear()\n",
        "            ax.plot(losses, color='blue', label='train loss', alpha=0.7)\n",
        "            ax.plot(range(0, len(losses), val_interval), val_losses, color='red', label='val loss', alpha=0.7)\n",
        "            ax.set_ylim(1, 4)\n",
        "            ax.legend()\n",
        "            dh.update(fig)\n",
        "    print('final loss:', loss.item(), 'final val loss:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Measure post training perplexity on validation set\n",
        "# Create function that receives a model, context length, and PPL sequence length, and returns the perplexity\n",
        "# The PPL sequence length is the number of characters the function uses to calculate the perplexity\n",
        "# We take the logits and calculate the cross entropy loss from scratch, then exponentiate it to get the perplexity\n",
        "# not only that, but we want the models to do this in actual inference\n",
        "def perplexity(model, seq_len, ppl_seq_len, batch_size=128, val_steps=1000):\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for _ in tqdm(range(val_steps)):\n",
        "            xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                logits, _ = model(xb, yb)\n",
        "            logits = logits.reshape(batch_size, seq_len, vocab_size)\n",
        "            logits = logits[:, :ppl_seq_len]\n",
        "            yb = yb[:, :ppl_seq_len]\n",
        "            # flatten logits and targets\n",
        "            logits = logits.reshape(batch_size*ppl_seq_len, vocab_size)\n",
        "            yb = yb.reshape(batch_size*ppl_seq_len)\n",
        "            # calculate cross entropy loss from scratch\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= val_steps\n",
        "        ppl = torch.exp(torch.tensor(val_loss))\n",
        "        return ppl.item(), val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classic Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "def apply_rotary_emb(\n",
        "    xq: torch.Tensor,\n",
        "    xk: torch.Tensor,\n",
        "    freqs_cis: torch.Tensor,\n",
        "):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    # freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    q_shape = [d if i == xq_.ndim - 2 or i == xq_.ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n",
        "    k_shape = [d if i == xq_.ndim - 2 or i == xk_.ndim - 1 else 1 for i, d in enumerate(xk_.shape)]\n",
        "    T_q = xq_.shape[-2] \n",
        "    q_freqs_cis = freqs_cis[-T_q:].view(*q_shape)\n",
        "    k_freqs_cis = freqs_cis.view(*k_shape)\n",
        "    xq_out = torch.view_as_real(xq_ * q_freqs_cis).flatten(xq.dim() - 1)\n",
        "    xk_out = torch.view_as_real(xk_ * k_freqs_cis).flatten(xq.dim() - 1)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "    \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention with AliBi in parallel \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        # block_mask for FlexAttention\n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            causal_mask = q_idx >= kv_idx\n",
        "            return causal_mask\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        _, _, T_past, _ = kv_cache[0].shape if kv_cache is not None and kv_cache[0] is not None else (0, 0, 0, 0)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        v = self.value(x) # (B,T,C)\n",
        "\n",
        "        # Split into heads\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "\n",
        "        if T == self.seq_len:\n",
        "            out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            # compute attention scores (\"affinities\")\n",
        "            wei = q @ k.transpose(-2,-1) # (B, H, 1, C/H) @ (B, H, C/H, T) -> (B, H, 1, T)\n",
        "            wei = wei * self.head_size ** -0.5 # scaled attention\n",
        "            wei = wei.masked_fill(self.tril[T_k-T:T_k, T_k-T:T_k] == 0, float('-inf')) # (B, T, T)\n",
        "            wei = F.softmax(wei, dim=-1) # (B, H, T, T)\n",
        "            # apply attention to values\n",
        "            out = wei @ v # (B, H, 1, T) @ (B, H, T, C/H) -> (B, H, 1, C/H)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C) # (B, H, T, C/H) -> (B, T, H, C/H) -> (B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "    \n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "    \n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_num = config.layer_num\n",
        "        self.head_num = config.head_num\n",
        "        self.seq_len = config.seq_len\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None):\n",
        "        B, T = idx.shape\n",
        "        _, _, T_past, _ = kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else (0, 0, 0, 0)\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = tok_embd\n",
        "        # go through blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i] = cache\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, V = logits.shape\n",
        "            logits = logits.view(B*T, V)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        if use_cache:\n",
        "            # initialize key-value cache\n",
        "            kv_cache = [(None, None) for _ in range(self.layer_num)]\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            # crop idx to the last seq_len tokens\n",
        "            idx_context = idx[:, -self.seq_len:]\n",
        "            for _ in range(max_new_tokens):\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context, kv_cache=kv_cache)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "                # since we have kv cache, only need to pass new token\n",
        "                idx_context = idx_next\n",
        "            return idx\n",
        "        else:\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            for _ in range(max_new_tokens):\n",
        "                #crop idx to the last seq_len tokens\n",
        "                idx_context = idx[:, -self.seq_len:]\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "            return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4775511"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "config = TransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6\n",
        ")\n",
        "m = TransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1)\n",
        "logits, loss = m(xb, yb)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de0c1946b5324752b0fe5bdcfb9a51cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/erland-home/Python_project/transformers_playground/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1917: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final loss: 1.0691111087799072 final val loss: 1.2072466731071472\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), 'models/TransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): TransformerLM(\n",
              "    (token_embedding_table): Embedding(87, 256)\n",
              "    (lm_head): Linear(in_features=256, out_features=87, bias=True)\n",
              "    (blocks): ModuleList(\n",
              "      (0-5): 6 x Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/TransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e0eededd891485b863673fe8e348032",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perplexity: 3.3366286754608154 loss: 1.2049609375\n"
          ]
        }
      ],
      "source": [
        "# calculate perplexity\n",
        "ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You will never do that!\n",
            "\n",
            "If you can be saying that the rest of us will be to save us...\n",
            "\n",
            "I can't forgive you because you came to see me.\n",
            "\n",
            "I'm sure you'll be a pretty good friend with me.\n",
            "\n",
            "I thought I was the only one who dreamed of me.\n",
            "\n",
            "I'd like to ask you this time.\n",
            "\n",
            "The book is a fantasy side that you're pretty surprised.\n",
            "\n",
            "If you have no idea what you want to tell me.\n",
            "\n",
            "I mean, you should think of my own life.\n",
            "\n",
            "It feels so surprised.\n",
            "\n",
            "It was all a drink.\n",
            "\n",
            "Should I tell you to stop stopping the magic power once you're done.\n",
            "\n",
            "I don't want to go out with you.\n",
            "\n",
            "You're really a mistake.\n",
            "\n",
            "What are you talking about?\n",
            "\n",
            "I have a talk about what I said would think.\n",
            "\n",
            "I saw you will wear the top out of the magic of the magic words.\n",
            "\n",
            "Why don't you try to stop me with that face?\n",
            "\n",
            "I was always to be a coincidence.\n",
            "\n",
            "In the magic case, I tried to stop you.\n",
            "\n",
            "I was worried about you all about that proper thing.\n",
            "\n",
            "I was thinking about working at the first step toward the story.\n",
            "\n",
            "I can see that I felt like I can do it a\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MTP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MTPTransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, n_future_tokens):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.n_future_tokens = n_future_tokens\n",
        "\n",
        "@torch.compiler.disable\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "@torch.compiler.disable\n",
        "def apply_rotary_emb(\n",
        "    xq: torch.Tensor,\n",
        "    xk: torch.Tensor,\n",
        "    freqs_cis: torch.Tensor,\n",
        "):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    # freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    q_shape = [d if i == xq_.ndim - 2 or i == xq_.ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n",
        "    k_shape = [d if i == xq_.ndim - 2 or i == xk_.ndim - 1 else 1 for i, d in enumerate(xk_.shape)]\n",
        "    T_q = xq_.shape[-2] \n",
        "    q_freqs_cis = freqs_cis[-T_q:].view(*q_shape)\n",
        "    k_freqs_cis = freqs_cis.view(*k_shape)\n",
        "    xq_out = torch.view_as_real(xq_ * q_freqs_cis).flatten(xq.dim() - 1)\n",
        "    xk_out = torch.view_as_real(xk_ * k_freqs_cis).flatten(xq.dim() - 1)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "    \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention with AliBi in parallel \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        # block_mask for FlexAttention\n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            causal_mask = q_idx >= kv_idx\n",
        "            return causal_mask\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        _, _, T_past, _ = kv_cache[0].shape if kv_cache is not None and kv_cache[0] is not None else (0, 0, 0, 0)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        v = self.value(x) # (B,T,C)\n",
        "\n",
        "        # Split into heads\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "\n",
        "        if T == self.seq_len:\n",
        "            out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            # compute attention scores (\"affinities\")\n",
        "            wei = q @ k.transpose(-2,-1) # (B, H, 1, C/H) @ (B, H, C/H, T) -> (B, H, 1, T)\n",
        "            wei = wei * self.head_size ** -0.5 # scaled attention\n",
        "            wei = wei.masked_fill(self.tril[T_k-T:T_k, T_k-T:T_k] == 0, float('-inf')) # (B, T, T)\n",
        "            wei = F.softmax(wei, dim=-1) # (B, H, T, T)\n",
        "            # apply attention to values\n",
        "            out = wei @ v # (B, H, 1, T) @ (B, H, T, C/H) -> (B, H, 1, C/H)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C) # (B, H, T, C/H) -> (B, T, H, C/H) -> (B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "    \n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "    \n",
        "class MTPTransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_num = config.layer_num\n",
        "        self.head_num = config.head_num\n",
        "        self.seq_len = config.seq_len\n",
        "        self.n_future_tokens = config.n_future_tokens\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num - self.n_future_tokens)])\n",
        "        self.extra_heads = nn.ModuleList([Block(config) for _ in range(self.n_future_tokens)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None, return_all_heads=False):\n",
        "        B, T = idx.shape\n",
        "        _, _, T_past, _ = kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else (0, 0, 0, 0)\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = tok_embd\n",
        "        # go through blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i] = cache\n",
        "        # get logits with linear layer\n",
        "\n",
        "        # MTP\n",
        "        trunk = x # (B,T,C)\n",
        "\n",
        "        latents = []\n",
        "        n_heads_to_use = self.n_future_tokens if return_all_heads else 1\n",
        "        prediction_heads = [self.blocks[-1]] + list(self.extra_heads)\n",
        "\n",
        "        for i, block in enumerate(prediction_heads[:n_heads_to_use]):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i + self.layer_num - self.n_future_tokens])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i + self.layer_num - self.n_future_tokens] = cache\n",
        "            latents.append(x)\n",
        "\n",
        "        x = torch.stack(latents, dim=-2) # (B, T, n_heads_to_use, C)\n",
        "\n",
        "        all_logits = self.lm_head(x) # (B, T, n_heads_to_use, V)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, n_heads_to_use, V = all_logits.shape\n",
        "            logits_flat = all_logits.view(-1, V)\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        logits = all_logits if return_all_heads else all_logits[:, :, 0, :] # Return the first head only\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        if use_cache:\n",
        "            # initialize key-value cache\n",
        "            kv_cache = [(None, None) for _ in range(self.layer_num)]\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            # crop idx to the last seq_len tokens\n",
        "            idx_context = idx[:, -self.seq_len:]\n",
        "            for _ in range(max_new_tokens):\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context, kv_cache=kv_cache)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "                # since we have kv cache, only need to pass new token\n",
        "                idx_context = idx_next\n",
        "            return idx\n",
        "        else:\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            for _ in range(max_new_tokens):\n",
        "                #crop idx to the last seq_len tokens\n",
        "                idx_context = idx[:, -self.seq_len:]\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "            return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4775511"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "n_future_tokens = 1\n",
        "config = MTPTransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6,\n",
        "    n_future_tokens=n_future_tokens\n",
        ")\n",
        "m = MTPTransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1, n_future_tokens)\n",
        "logits, loss = m(xb, yb, return_all_heads=True)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f236c66500b420fbbee0c612296966b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final loss: 1.0742982625961304 final val loss: 1.213886284828186\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = MTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), 'models/MTPTransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): MTPTransformerLM(\n",
              "    (token_embedding_table): Embedding(87, 256)\n",
              "    (lm_head): Linear(in_features=256, out_features=87, bias=True)\n",
              "    (blocks): ModuleList(\n",
              "      (0-4): 5 x Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (extra_heads): ModuleList(\n",
              "      (0): Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model\n",
        "model = MTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/MTPTransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7032311b2b894316aa7dd649b6705882",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perplexity: 3.348928928375244 loss: 1.208640625\n"
          ]
        }
      ],
      "source": [
        "# calculate perplexity\n",
        "ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n",
            "You will never be sold by your friends and worked out.\n",
            "\n",
            "Why are they here?\n",
            "\n",
            "I won't let you try to survive the new land.\n",
            "\n",
            "You don't need to be the one who was a bit stronger than that?\n",
            "\n",
            "I won't be able to do that.\n",
            "\n",
            "Why don't you come to see that to help you?\n",
            "\n",
            "I think that I thought I was able to be that bad at the captain of the ground.\n",
            "\n",
            "I can't treat you to the control of the Secrets will be the worst position of the first place.\n",
            "\n",
            "I wonder if it can't be a total power to see the Secret of the Sea God.\n",
            "\n",
            "But I don't think that I want to see it on a day.\n",
            "\n",
            "The Secret said that we want to show the problem here.\n",
            "\n",
            "He said that he looked in a relationship with him at the first time on the same time.\n",
            "\n",
            "Allow us to have to do is think of it, control of the main station.\n",
            "\n",
            "The Secret is a mistake.\n",
            "\n",
            "The Sea God of Tenkaidou is a man or something else in the stars of the dead face.\n",
            "\n",
            "It's a perfect rest for the Soul Reaper\n",
            "\n",
            "of the Soul Reapers are already served to the very eyes and submitted to be a bit longer,\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Memory MTP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MTPTransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, n_future_tokens):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.n_future_tokens = n_future_tokens\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "@torch.compiler.disable\n",
        "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    \n",
        "    # Reshape freqs_cis for broadcasting\n",
        "    shape = [1] * (xq_.ndim - 2) + list(freqs_cis.shape)\n",
        "    freqs_cis = freqs_cis.view(*shape)\n",
        "\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        \n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            return q_idx >= kv_idx\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        \n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "        \n",
        "        if T == self.seq_len and self.causal_mask is not None:\n",
        "             out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            wei = q @ k.transpose(-2,-1) * (self.head_size**-0.5)\n",
        "            wei = wei.masked_fill(self.tril[:T, :T_k] == 0, float('-inf'))\n",
        "            wei = F.softmax(wei, dim=-1)\n",
        "            out = wei @ v\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "\n",
        "# ---- NEW: Custom Autograd Function for MEMORY-EFFICIENT TRAINING ----\n",
        "\n",
        "class SequentialHeadsCustomBackward(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, trunk_output, lm_head, *prediction_heads):\n",
        "        # Save modules and non-tensor arguments for the backward pass.\n",
        "        ctx.prediction_heads = prediction_heads\n",
        "        ctx.lm_head = lm_head\n",
        "        # Save tensors needed for the backward pass.\n",
        "        ctx.save_for_backward(trunk_output)\n",
        "\n",
        "        # Standard sequential forward pass\n",
        "        latents = []\n",
        "        for head in prediction_heads:\n",
        "            latent, _ = head(trunk_output, kv_cache=None)\n",
        "            latents.append(latent)\n",
        "        \n",
        "        latents_stacked = torch.stack(latents, dim=-2)\n",
        "        all_logits = lm_head(latents_stacked)\n",
        "        return all_logits\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        trunk_output, = ctx.saved_tensors\n",
        "        prediction_heads = ctx.prediction_heads\n",
        "        lm_head = ctx.lm_head\n",
        "        \n",
        "        d = trunk_output.detach().requires_grad_(True)\n",
        "        grad_output_per_head = grad_output.unbind(dim=2)\n",
        "\n",
        "        for i, head in enumerate(prediction_heads):\n",
        "            with torch.enable_grad():\n",
        "                head_latent, _ = head(d)\n",
        "                head_logits = lm_head(head_latent)\n",
        "            \n",
        "            head_logits.backward(gradient=grad_output_per_head[i])\n",
        "            \n",
        "        num_nones = 1 + len(prediction_heads) # For lm_head + *prediction_heads\n",
        "        return (d.grad,) + (None,) * num_nones\n",
        "\n",
        "# ---- REFACTORED MTPTransformerLM with custom backward logic ----\n",
        "\n",
        "class MTPTransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        \n",
        "        # Clean separation between trunk and heads\n",
        "        num_trunk_blocks = config.layer_num - config.n_future_tokens\n",
        "        self.trunk_blocks = nn.ModuleList([Block(config) for _ in range(num_trunk_blocks)])\n",
        "        self.prediction_heads = nn.ModuleList([Block(config) for _ in range(config.n_future_tokens)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None, return_all_heads=False, use_custom_backward=True):\n",
        "        B, T = idx.shape\n",
        "        tok_embd = self.token_embedding_table(idx)\n",
        "        x = tok_embd\n",
        "        \n",
        "        # 1. Shared Trunk\n",
        "        for i, block in enumerate(self.trunk_blocks):\n",
        "            x, _ = block(x) # Simplified kv_cache for clarity\n",
        "        trunk = x\n",
        "\n",
        "        # 2. Prediction Heads\n",
        "        n_heads_to_use = self.config.n_future_tokens if return_all_heads else 1\n",
        "        \n",
        "        if self.training and return_all_heads and use_custom_backward:\n",
        "            # Pass only the heads we intend to use to the custom function\n",
        "            active_heads = self.prediction_heads[:n_heads_to_use]\n",
        "            all_logits = SequentialHeadsCustomBackward.apply(trunk, self.lm_head, *active_heads)\n",
        "        else:\n",
        "            latents = []\n",
        "            for i, block in enumerate(self.prediction_heads[:n_heads_to_use]):\n",
        "                x_head, _ = block(trunk)\n",
        "                latents.append(x_head)\n",
        "            x = torch.stack(latents, dim=-2)\n",
        "            all_logits = self.lm_head(x)\n",
        "        \n",
        "        # 3. Loss Calculation\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, H, V = all_logits.shape\n",
        "            logits_flat = all_logits.view(B * T * H, V)\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        logits = all_logits if return_all_heads else all_logits.squeeze(2)\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.seq_len else idx[:, -self.config.seq_len:]\n",
        "            # Note: generate calls with return_all_heads=False, so it doesn't use the custom BWD path\n",
        "            logits, _ = self(idx_cond, return_all_heads=False)\n",
        "            logits = logits[:, -1, :] / temperature if temperature > 0 else logits[:, -1, :]\n",
        "            \n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4775511"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "n_future_tokens = 3\n",
        "config = MTPTransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6,\n",
        "    n_future_tokens=n_future_tokens\n",
        ")\n",
        "m = MTPTransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1, n_future_tokens)\n",
        "logits, loss = m(xb, yb, return_all_heads=True)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58c5292dc7684b939949d9157311c0cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = MTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), 'models/SavingMemoryMTPTransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): MTPTransformerLM(\n",
              "    (token_embedding_table): Embedding(87, 256)\n",
              "    (lm_head): Linear(in_features=256, out_features=87, bias=True)\n",
              "    (blocks): ModuleList(\n",
              "      (0-4): 5 x Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (extra_heads): ModuleList(\n",
              "      (0): Block(\n",
              "        (sa_heads): MultiHeadAttention(\n",
              "          (key): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (query): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (value): Linear(in_features=256, out_features=256, bias=False)\n",
              "          (o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ff_layer): FeedForward(\n",
              "          (lin_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (lin_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (sa_norm): RMSNorm()\n",
              "        (ff_norm): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load model\n",
        "model = MTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/SavingMemoryMTPTransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7032311b2b894316aa7dd649b6705882",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "perplexity: 3.348928928375244 loss: 1.208640625\n"
          ]
        }
      ],
      "source": [
        "# calculate perplexity\n",
        "ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n",
            "You will never be sold by your friends and worked out.\n",
            "\n",
            "Why are they here?\n",
            "\n",
            "I won't let you try to survive the new land.\n",
            "\n",
            "You don't need to be the one who was a bit stronger than that?\n",
            "\n",
            "I won't be able to do that.\n",
            "\n",
            "Why don't you come to see that to help you?\n",
            "\n",
            "I think that I thought I was able to be that bad at the captain of the ground.\n",
            "\n",
            "I can't treat you to the control of the Secrets will be the worst position of the first place.\n",
            "\n",
            "I wonder if it can't be a total power to see the Secret of the Sea God.\n",
            "\n",
            "But I don't think that I want to see it on a day.\n",
            "\n",
            "The Secret said that we want to show the problem here.\n",
            "\n",
            "He said that he looked in a relationship with him at the first time on the same time.\n",
            "\n",
            "Allow us to have to do is think of it, control of the main station.\n",
            "\n",
            "The Secret is a mistake.\n",
            "\n",
            "The Sea God of Tenkaidou is a man or something else in the stars of the dead face.\n",
            "\n",
            "It's a perfect rest for the Soul Reaper\n",
            "\n",
            "of the Soul Reapers are already served to the very eyes and submitted to be a bit longer,\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Investigate Saving Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List\n",
        "import copy\n",
        "\n",
        "\n",
        "class DSMTPTransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, n_future_tokens):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.n_future_tokens = n_future_tokens\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "@torch.compiler.disable\n",
        "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    \n",
        "    # Reshape freqs_cis for broadcasting\n",
        "    shape = [1] * (xq_.ndim - 2) + list(freqs_cis.shape)\n",
        "    freqs_cis = freqs_cis.view(*shape)\n",
        "\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        \n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            return q_idx >= kv_idx\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        \n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "        \n",
        "        if T == self.seq_len:\n",
        "             out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            wei = q @ k.transpose(-2,-1) * (self.head_size**-0.5)\n",
        "            wei = wei.masked_fill(self.tril[:T, :T_k] == 0, float('-inf'))\n",
        "            wei = F.softmax(wei, dim=-1)\n",
        "            out = wei @ v\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "\n",
        "class DSMTPTransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        \n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num - config.n_future_tokens)])\n",
        "        self.extra_heads = nn.ModuleList([Block(config) for _ in range(config.n_future_tokens)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None, return_all_heads=False, use_custom_backward=True):\n",
        "        B, T = idx.shape\n",
        "        tok_embd = self.token_embedding_table(idx)\n",
        "        x = tok_embd\n",
        "        \n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "        trunk = x\n",
        "\n",
        "        n_heads_to_use = self.config.n_future_tokens if return_all_heads else 1\n",
        "        prediction_heads = [self.blocks[-1]] + list(self.extra_heads) if len(self.blocks) > 0 else list(self.extra_heads)\n",
        "\n",
        "        if self.training and return_all_heads and use_custom_backward:\n",
        "            all_logits = SequentialHeadsCustomBackward.apply(trunk, self.lm_head, *prediction_heads[:n_heads_to_use])\n",
        "        else:\n",
        "            latents = []\n",
        "            for i, block in enumerate(prediction_heads[:n_heads_to_use]):\n",
        "                x_head, _ = block(trunk)\n",
        "                latents.append(x_head)\n",
        "            x = torch.stack(latents, dim=-2)\n",
        "            all_logits = self.lm_head(x)\n",
        "        \n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, V = all_logits.shape[0], all_logits.shape[1], all_logits.shape[-1]\n",
        "            logits_flat = all_logits.view(B * T * n_heads_to_use, V)\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        logits = all_logits if return_all_heads else all_logits[:, :, 0, :]\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        # This function remains largely the same, as it calls forward with return_all_heads=False\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.seq_len else idx[:, -self.config.seq_len:]\n",
        "            logits, _ = self(idx_cond, return_all_heads=False)\n",
        "            logits = logits[:, -1, :] / temperature if temperature > 0 else logits[:, -1, :]\n",
        "            \n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSeek MTP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List\n",
        "import copy\n",
        "\n",
        "# targets: [B, n_future_tokens, S]\n",
        "\n",
        "class DSMTPTransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, n_future_tokens):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.n_future_tokens = n_future_tokens\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "@torch.compiler.disable\n",
        "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    \n",
        "    # Reshape freqs_cis for broadcasting\n",
        "    shape = [1] * (xq_.ndim - 2) + list(freqs_cis.shape)\n",
        "    freqs_cis = freqs_cis.view(*shape)\n",
        "\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        \n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            return q_idx >= kv_idx\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        \n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "        \n",
        "        if T == self.seq_len:\n",
        "             out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            wei = q @ k.transpose(-2,-1) * (self.head_size**-0.5)\n",
        "            wei = wei.masked_fill(self.tril[:T, :T_k] == 0, float('-inf'))\n",
        "            wei = F.softmax(wei, dim=-1)\n",
        "            out = wei @ v\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "\n",
        "class DSMTPTransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        \n",
        "        # The main body of the model\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num - config.n_future_tokens)])\n",
        "        # The prediction heads that branch off\n",
        "        self.extra_heads = nn.ModuleList([Block(config) for _ in range(config.n_future_tokens)])\n",
        "        self.projection_head = nn.ModuleList([nn.Linear(2 * config.embed_size, config.embed_size) for _ in range(config.n_future_tokens)])\n",
        "        self.norms_1 = nn.ModuleList([RMSNorm(config.embed_size) for _ in range(config.n_future_tokens)])\n",
        "        self.norms_2 = nn.ModuleList([RMSNorm(config.embed_size) for _ in range(config.n_future_tokens)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None, return_all_heads=True, use_custom_backward=True):\n",
        "        B, n_future_tokens, T = idx.shape\n",
        "\n",
        "        tok_embd = self.token_embedding_table(idx) # B, n_future_tokens, T, C\n",
        "        # print(tok_embd.shape)\n",
        "        x = tok_embd[:, 0, :, :]  \n",
        "        \n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "\n",
        "        n_heads_to_use = self.config.n_future_tokens if return_all_heads else 1\n",
        "        prediction_heads = list(self.extra_heads)\n",
        "\n",
        "        latents = []\n",
        "        for i, block in enumerate(prediction_heads[:n_heads_to_use]):\n",
        "            # print(f\"1. {x.shape = }\")\n",
        "\n",
        "            # print(f\"2. {x.shape = }\")\n",
        "            if i > 0:\n",
        "                x = self.norms_1[i](x)\n",
        "                new_input = self.norms_2[i](tok_embd[:, i, :, :].detach())\n",
        "                x = torch.cat((x, new_input), dim=-1) # B, S, 2\n",
        "                # print(f\"3. {x.shape = }\")\n",
        "                x = self.projection_head[i](x)\n",
        "                # print(f\"4. {x.shape = }\")\n",
        "            x, _ = block(x)\n",
        "\n",
        "            # print(f\"5. {x.shape = }\")\n",
        "            latents.append(x)\n",
        "        x = torch.stack(latents, dim=-2)\n",
        "        # print(f\"{x.shape  = }\")\n",
        "        all_logits = self.lm_head(x)\n",
        "        \n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, V = all_logits.shape[0], all_logits.shape[1], all_logits.shape[-1]\n",
        "            logits_flat = all_logits.view(B * T * n_heads_to_use, V)\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        # print(f\"{idx = }\")\n",
        "        # print(f\"{targets = }\")\n",
        "\n",
        "        logits = all_logits if return_all_heads else all_logits[:, :, 0, :]\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.seq_len else idx[:, -self.config.seq_len:]\n",
        "            logits, _ = self(idx_cond, return_all_heads=False)\n",
        "            logits = logits[:, -1, :] / temperature if temperature > 0 else logits[:, -1, :]\n",
        "            \n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5171031"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "n_future_tokens = 3\n",
        "config = DSMTPTransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6,\n",
        "    n_future_tokens=n_future_tokens\n",
        ")\n",
        "m = DSMTPTransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1, n_future_tokens)\n",
        "logits, loss = m(xb, yb, return_all_heads=True)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf268751a8174d7691f95bde3fdfc545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model.to(device)\n\u001b[32m      5\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=\u001b[32m2e-3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_future_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, seq_len, batch_size, total_steps, val_steps, val_interval, n_future_tokens)\u001b[39m\n\u001b[32m     16\u001b[39m loss.backward()\n\u001b[32m     17\u001b[39m optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m bar.set_description(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_losses[-\u001b[32m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mval_losses\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m losses.append(loss.item())\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m steps % val_interval == \u001b[32m0\u001b[39m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# Calculate validation loss\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = DSMTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps, n_future_tokens=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSeek MTP Shared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List\n",
        "import copy\n",
        "\n",
        "# targets: [B, n_future_tokens, S]\n",
        "\n",
        "class DSMTPTransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, n_future_tokens):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.n_future_tokens = n_future_tokens\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "@torch.compiler.disable\n",
        "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    \n",
        "    # Reshape freqs_cis for broadcasting\n",
        "    shape = [1] * (xq_.ndim - 2) + list(freqs_cis.shape)\n",
        "    freqs_cis = freqs_cis.view(*shape)\n",
        "\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*4)\n",
        "        self.lin_2 = nn.Linear(config.embed_size*4, config.embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size)\n",
        "        \n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            return q_idx >= kv_idx\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        \n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "        \n",
        "        if T == self.seq_len:\n",
        "             out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            wei = q @ k.transpose(-2,-1) * (self.head_size**-0.5)\n",
        "            wei = wei.masked_fill(self.tril[:T, :T_k] == 0, float('-inf'))\n",
        "            wei = F.softmax(wei, dim=-1)\n",
        "            out = wei @ v\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "\n",
        "class DSMTPTransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size)\n",
        "        \n",
        "        # The main body of the model\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num - config.n_future_tokens)])\n",
        "        # The prediction heads that branch off\n",
        "        self.extra_heads = nn.ModuleList([Block(config) for _ in range(config.n_future_tokens)])\n",
        "        self.projection_head = nn.ModuleList([nn.Linear(2 * config.embed_size, config.embed_size) for _ in range(config.n_future_tokens)])\n",
        "        self.shared_rms_norm = RMSNorm(config.embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None, return_all_heads=True, use_custom_backward=True):\n",
        "        B, n_future_tokens, T = idx.shape\n",
        "\n",
        "        tok_embd = self.token_embedding_table(idx) # B, n_future_tokens, T, C\n",
        "        # print(tok_embd.shape)\n",
        "        x = tok_embd[:, 0, :, :]  \n",
        "        \n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "\n",
        "        n_heads_to_use = self.config.n_future_tokens if return_all_heads else 1\n",
        "        prediction_heads = list(self.extra_heads)\n",
        "\n",
        "        latents = []\n",
        "        for i, block in enumerate(prediction_heads[:n_heads_to_use]):\n",
        "            # print(f\"1. {x.shape = }\")\n",
        "\n",
        "            # print(f\"2. {x.shape = }\")\n",
        "            if i > 0:\n",
        "                x = self.shared_rms_norm(x)\n",
        "                new_input = self.shared_rms_norm(tok_embd[:, i, :, :].detach())\n",
        "                x = torch.cat((x, new_input), dim=-1) # B, S, 2\n",
        "                # print(f\"3. {x.shape = }\")\n",
        "                x = self.projection_head[i](x)\n",
        "                # print(f\"4. {x.shape = }\")\n",
        "            x, _ = block(x)\n",
        "\n",
        "            # print(f\"5. {x.shape = }\")\n",
        "            latents.append(x)\n",
        "        x = torch.stack(latents, dim=-2)\n",
        "        # print(f\"{x.shape  = }\")\n",
        "        all_logits = self.lm_head(x)\n",
        "        \n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, V = all_logits.shape[0], all_logits.shape[1], all_logits.shape[-1]\n",
        "            logits_flat = all_logits.view(B * T * n_heads_to_use, V)\n",
        "            targets_flat = targets.reshape(-1)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        # print(f\"{idx = }\")\n",
        "        # print(f\"{targets = }\")\n",
        "\n",
        "        logits = all_logits if return_all_heads else all_logits[:, :, 0, :]\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.seq_len else idx[:, -self.config.seq_len:]\n",
        "            logits, _ = self(idx_cond, return_all_heads=False)\n",
        "            logits = logits[:, -1, :] / temperature if temperature > 0 else logits[:, -1, :]\n",
        "            \n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5169751"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "n_future_tokens = 3\n",
        "config = DSMTPTransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6,\n",
        "    n_future_tokens=n_future_tokens\n",
        ")\n",
        "m = DSMTPTransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1, n_future_tokens)\n",
        "logits, loss = m(xb, yb, return_all_heads=True)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "316f84b117f84d7190e585a1608da742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = DSMTPTransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps, n_future_tokens=3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
