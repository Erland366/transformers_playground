{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
        "import triton\n",
        "import triton.language as tl\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "torch.manual_seed(69)\n",
        "torch.set_printoptions(profile=\"short\", sci_mode=False, linewidth=100000)\n",
        "torch.set_float32_matmul_precision('high')\n",
        "# this script is configured to run on a RTX 3060 12GB GPU. you'll want to adjust the model sizes and batch sizes for other devices\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = torch.device('cpu')\n",
        "plt.rcParams['figure.figsize'] = [8, 6]\n",
        "plt.rcParams['figure.dpi'] = 50\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['xtick.minor.visible'] = True\n",
        "plt.rcParams['ytick.minor.visible'] = True\n",
        "# make 'models' folder to save trained models if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  39526018\n"
          ]
        }
      ],
      "source": [
        "# we use this 40mb file of concatenated anime subtitles as our dataset\n",
        "# just the right size for toy experiments like this I think\n",
        "with open('animesubs.txt', 'r', encoding='latin') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open your mind. Open your mind.\n",
            "\n",
            "Far beyond the deep blue Earth, you and I shall meet...\n",
            "\n",
            "AH! MY GODDESS\n",
            "\n",
            "A snow-white feather comes fluttering down, swaying gently in the air.\n",
            "\n",
            "Without holding back, I want to envelope you, my one and only love.\n",
            "\n",
            "I know I have the power to protect the one I love, right here in my hands.\n",
            "\n",
            "Open your mind. Just as I've always dreamed.\n",
            "\n",
            "Let the wind carry off your hopes, faraway.\n",
            "\n",
            "I have wings nobody can see. Look, you have them, too.\n",
            "\n",
            "They'll take us to where we ca\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 86 \n",
            " !'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|Â”\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, '*': 6, '+': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '<': 24, '=': 25, '>': 26, '?': 27, '@': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '[': 55, ']': 56, '_': 57, 'a': 58, 'b': 59, 'c': 60, 'd': 61, 'e': 62, 'f': 63, 'g': 64, 'h': 65, 'i': 66, 'j': 67, 'k': 68, 'l': 69, 'm': 70, 'n': 71, 'o': 72, 'p': 73, 'q': 74, 'r': 75, 's': 76, 't': 77, 'u': 78, 'v': 79, 'w': 80, 'x': 81, 'y': 82, 'z': 83, '|': 84, '\\x94': 85, '': 86}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: '*', 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '<', 25: '=', 26: '>', 27: '?', 28: '@', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '|', 85: '\\x94', 86: ''}\n",
            "encoded: [43, 73, 62, 71, 1, 82, 72, 78, 75, 1, 70, 66, 71, 61, 10, 1, 43, 73, 62, 71]\n",
            "decoded: Open your mind. Open\n",
            "vocab size: 87\n"
          ]
        }
      ],
      "source": [
        "# yes, all language models will be character level, which isn't ideal but it's good for simplicity\n",
        "# very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([39526018])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  1, 43, 73, 62, 71,  1, 82, 72, 78, 75,  1, 70, 66, 71, 61, 10,  0,  0, 34, 58, 75,  1, 59, 62, 82, 72, 71, 61,  1, 77, 65, 62,  1, 61, 62, 62, 73,  1, 59, 69, 78, 62,  1, 33, 58, 75, 77, 65,  8,  1, 82, 72, 78,  1, 58, 71, 61,  1, 37,  1, 76, 65, 58, 69, 69,  1, 70, 62, 62, 77, 10, 10, 10,  0,  0, 29, 36,  2,  1, 41, 53,  1, 35, 43, 32])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([39130757]) torch.Size([395261])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.99)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([43, 73, 62, 71,  1, 82, 72, 78, 75])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len = 8\n",
        "train_data[:seq_len+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([2, 64])\n",
            "tensor([[64,  1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71],\n",
            "        [62, 70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([2, 64])\n",
            "tensor([[ 1, 72, 78, 75,  1, 66, 71, 77, 62, 75, 71, 76, 65, 66, 73, 76, 10,  0,  0, 48, 65, 62,  1, 71, 66, 64, 65, 77,  1, 37, 66, 61, 58,  1, 64, 72, 77,  1, 77, 65, 62,  1, 75, 62, 76, 78, 69, 77, 76,  1, 72, 63,  1, 77, 65, 62,  1, 62, 81, 58, 70, 66, 71, 58],\n",
            "        [70,  2,  0,  0, 37, 77,  1, 69, 72, 72, 68, 76,  1, 69, 66, 68, 62,  1, 80, 62,  1, 77, 72, 72, 68,  1, 60, 58, 75, 62,  1, 72, 63,  1, 77, 65, 62, 70, 10,  0,  0, 48, 65, 72, 76, 62,  1, 64, 78, 82, 76,  1, 80, 62, 75, 62,  1, 66, 71, 60, 75, 62, 61, 66]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, seq_len, batch_size=4):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    # targets are just inputs shifted by 1\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - seq_len, (batch_size,))\n",
        "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "xb, yb = get_batch('train', 64, 2)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "327680000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make all steps, sequence lengths, and batch size the same\n",
        "total_steps = 5000\n",
        "seq_len = 256\n",
        "batch_size = 256 # these are small models so we can use large batch sizes to fully utilize the GPU\n",
        "# should cover around 2x the dataset\n",
        "total_steps * seq_len * batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, optimizer, seq_len, batch_size, total_steps, val_steps=10, val_interval=50):\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    # live plot\n",
        "    fig, ax = plt.subplots()\n",
        "    dh = display.display(fig, display_id=True)\n",
        "    for steps in (bar := tqdm(range(total_steps))):  # increase number of steps for good results...\n",
        "        # sample a batch of data\n",
        "        xb, yb = get_batch('train', seq_len=seq_len, batch_size=batch_size)\n",
        "\n",
        "        # evaluate the loss\n",
        "        logits, loss = model(xb, yb)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bar.set_description(f\"loss: {loss.item():.2f}, val loss: {val_losses[-1] if val_losses else 0:.2f}\")\n",
        "        losses.append(loss.item())\n",
        "        if steps % val_interval == 0:\n",
        "            # Calculate validation loss\n",
        "            with torch.no_grad():\n",
        "                val_loss = 0\n",
        "                for _ in range(val_steps):\n",
        "                    xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "                    _, loss = model(xb, yb)\n",
        "                    val_loss += loss.item()\n",
        "                val_loss /= val_steps\n",
        "                val_losses.append(val_loss)\n",
        "            ax.clear()\n",
        "            ax.plot(losses, color='blue', label='train loss', alpha=0.7)\n",
        "            ax.plot(range(0, len(losses), val_interval), val_losses, color='red', label='val loss', alpha=0.7)\n",
        "            ax.set_ylim(0, 4)\n",
        "            ax.legend()\n",
        "            dh.update(fig)\n",
        "    print('final loss:', loss.item(), 'final val loss:', val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Measure post training perplexity on validation set\n",
        "# Create function that receives a model, context length, and PPL sequence length, and returns the perplexity\n",
        "# The PPL sequence length is the number of characters the function uses to calculate the perplexity\n",
        "# We take the logits and calculate the cross entropy loss from scratch, then exponentiate it to get the perplexity\n",
        "# not only that, but we want the models to do this in actual inference\n",
        "def perplexity(model, seq_len, ppl_seq_len, batch_size=128, val_steps=1000):\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for _ in tqdm(range(val_steps)):\n",
        "            xb, yb = get_batch('val', seq_len=seq_len, batch_size=batch_size)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
        "                logits, _ = model(xb, yb)\n",
        "            logits = logits.reshape(batch_size, seq_len, vocab_size)\n",
        "            logits = logits[:, :ppl_seq_len]\n",
        "            yb = yb[:, :ppl_seq_len]\n",
        "            # flatten logits and targets\n",
        "            logits = logits.reshape(batch_size*ppl_seq_len, vocab_size)\n",
        "            yb = yb.reshape(batch_size*ppl_seq_len)\n",
        "            # calculate cross entropy loss from scratch\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= val_steps\n",
        "        ppl = torch.exp(torch.tensor(val_loss))\n",
        "        return ppl.item(), val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classic Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerConfig:\n",
        "    def __init__(self, vocab_size, seq_len, embed_size, head_num, layer_num, hidden_mult=4):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.seq_len = seq_len\n",
        "        self.embed_size = embed_size\n",
        "        self.head_num = head_num\n",
        "        self.layer_num = layer_num\n",
        "        self.hidden_mult = hidden_mult\n",
        "\n",
        "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n",
        "    freqs = torch.outer(t, freqs)\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
        "    return freqs_cis.to(device)\n",
        "\n",
        "def apply_rotary_emb(\n",
        "    xq: torch.Tensor,\n",
        "    xk: torch.Tensor,\n",
        "    freqs_cis: torch.Tensor,\n",
        "):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    # freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    q_shape = [d if i == xq_.ndim - 2 or i == xq_.ndim - 1 else 1 for i, d in enumerate(xq_.shape)]\n",
        "    k_shape = [d if i == xq_.ndim - 2 or i == xk_.ndim - 1 else 1 for i, d in enumerate(xk_.shape)]\n",
        "    T_q = xq_.shape[-2] \n",
        "    q_freqs_cis = freqs_cis[-T_q:].view(*q_shape)\n",
        "    k_freqs_cis = freqs_cis.view(*k_shape)\n",
        "    xq_out = torch.view_as_real(xq_ * q_freqs_cis).flatten(xq.dim() - 1)\n",
        "    xk_out = torch.view_as_real(xk_ * k_freqs_cis).flatten(xq.dim() - 1)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "    \n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(config.embed_size, config.embed_size*config.hidden_mult, bias=False)\n",
        "        self.lin_2 = nn.Linear(config.embed_size, config.embed_size*config.hidden_mult, bias=False)\n",
        "        self.lin_3 = nn.Linear(config.embed_size*config.hidden_mult, config.embed_size, bias=False)\n",
        "        self.silu = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lin_1(x)\n",
        "        x2 = self.lin_2(x)\n",
        "        x = self.silu(x1) * x2\n",
        "        x = self.lin_3(x)\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.seq_len = config.seq_len\n",
        "        self.head_num = config.head_num\n",
        "        self.head_size = config.embed_size // config.head_num\n",
        "        self.query = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.key = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.value = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        self.o = nn.Linear(config.embed_size, config.embed_size, bias=False)\n",
        "        # block_mask for FlexAttention\n",
        "        def causal(b, h, q_idx, kv_idx):\n",
        "            causal_mask = q_idx >= kv_idx\n",
        "            return causal_mask\n",
        "        self.causal_mask = create_block_mask(causal, B=None, H=None, Q_LEN=config.seq_len, KV_LEN=config.seq_len)\n",
        "        self.freqs_cis = precompute_freqs_cis(config.embed_size//config.head_num, config.seq_len)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(config.seq_len, config.seq_len)))\n",
        "\n",
        "    def forward(self, x, kv_cache=None):\n",
        "        B, T, C = x.shape\n",
        "        _, _, T_past, _ = kv_cache[0].shape if kv_cache is not None and kv_cache[0] is not None else (0, 0, 0, 0)\n",
        "        q = self.query(x) # (B, T, C)\n",
        "        k = self.key(x)   # (B, T, C)\n",
        "        v = self.value(x) # (B, T, C)\n",
        "\n",
        "        # Split into heads\n",
        "        q = q.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        k = k.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "        v = v.view(B, T, self.head_num, self.head_size).transpose(1, 2) # (B, H, T, C/H)\n",
        "\n",
        "        if kv_cache is not None:\n",
        "            k_past, v_past = kv_cache\n",
        "            if k_past is not None:\n",
        "                k = torch.cat((k_past, k), dim=2)\n",
        "                v = torch.cat((v_past, v), dim=2)\n",
        "            if k.shape[-2] > self.seq_len:\n",
        "                k = k[:, :, -self.seq_len:]\n",
        "                v = v[:, :, -self.seq_len:]\n",
        "            kv_cache = (k, v)\n",
        "        T_k = k.shape[-2]\n",
        "        q, k = apply_rotary_emb(q, k, self.freqs_cis[:T_k])\n",
        "\n",
        "        if T == self.seq_len: # only in training\n",
        "            out = flex_attention(q, k, v, block_mask=self.causal_mask)\n",
        "        else:\n",
        "            # compute attention scores (\"affinities\")\n",
        "            wei = q @ k.transpose(-2,-1) # (B, H, Tq, C/H) @ (B, H, C/H, Tk) -> (B, H, Tq, Tk)\n",
        "            wei = wei * self.head_size ** -0.5 # scaled attention\n",
        "            wei = wei.masked_fill(self.tril[T_k-T:T_k, :T_k] == 0, float('-inf')) # (B, Tq, Tk)\n",
        "            wei = F.softmax(wei, dim=-1) # (B, H, Tq, Tk)\n",
        "            # apply attention to values\n",
        "            out = wei @ v # (B, H, Tq, Tk) @ (B, H, Tk, C/H) -> (B, H, Tq, C/H)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C) # (B, H, Tq, C/H) -> (B, Tq, H, C/H) -> (B, Tq, C)\n",
        "        out = self.o(out)\n",
        "        return out, kv_cache\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(config)\n",
        "        self.ff_layer = FeedForward(config)\n",
        "        self.sa_norm = RMSNorm(config.embed_size)\n",
        "        self.ff_norm = RMSNorm(config.embed_size)\n",
        "    \n",
        "    def forward(self, x, kv_cache=None):\n",
        "        a, kv_cache = self.sa_heads(self.sa_norm(x), kv_cache)\n",
        "        h = x + a\n",
        "        o = h + self.ff_layer(self.ff_norm(h))\n",
        "        return o, kv_cache\n",
        "    \n",
        "class TransformerLM(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer_num = config.layer_num\n",
        "        self.head_num = config.head_num\n",
        "        self.seq_len = config.seq_len\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(config.vocab_size, config.embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(config.embed_size, config.vocab_size, bias=False)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None, kv_cache=None):\n",
        "        B, T = idx.shape\n",
        "        # print(\"Input shape:\", idx.shape)\n",
        "        # print(\"KV cache shape:\", kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else None)\n",
        "        _, _, T_past, _ = kv_cache[0][0].shape if kv_cache is not None and kv_cache[0][0] is not None else (0, 0, 0, 0)\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        x = tok_embd\n",
        "        # go through blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x, cache = block(x, None if kv_cache is None else kv_cache[i])\n",
        "            if kv_cache is not None:\n",
        "                kv_cache[i] = cache\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,V)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, V = logits.shape\n",
        "            logits = logits.view(B*T, V)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, temperature=1, use_cache=True, use_klcc=False, klcc_cutoff=None, klcc_window_size=None, klcc_steps=None, klcc_lr=1e-5):\n",
        "        if use_cache:\n",
        "            # initialize key-value cache\n",
        "            kv_cache = [(None, None) for _ in range(self.layer_num)]\n",
        "            # idx is (B, T) array of indices in the current context\n",
        "            # crop idx to the last seq_len tokens\n",
        "            idx_context = idx[:, -self.seq_len:]\n",
        "            if use_klcc:\n",
        "                all_logits = None\n",
        "            for _ in range(max_new_tokens):\n",
        "                # get the predictions\n",
        "                logits, loss = self(idx_context, kv_cache=kv_cache)\n",
        "                if use_klcc:\n",
        "                    all_logits = logits if all_logits is None else torch.cat((all_logits, logits), dim=1)\n",
        "                # focus only on the last time step\n",
        "                logits = logits[:, -1, :] # becomes (B, C)\n",
        "                # apply temperature\n",
        "                logits = logits / temperature if temperature > 0 else logits\n",
        "                # apply softmax to get probabilities\n",
        "                probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "                # sample from the distribution\n",
        "                idx_next = torch.multinomial(probs, num_samples=1) if temperature > 0 else torch.argmax(probs, dim=-1, keepdim=True) # (B, 1)\n",
        "                # do KL context compression\n",
        "                if use_klcc and kv_cache[0][0].shape[2] >= klcc_cutoff:\n",
        "                    self.train()\n",
        "                    klcc_optimizer = torch.optim.AdamW(self.parameters(), lr=klcc_lr)\n",
        "                    for _ in range(klcc_steps):\n",
        "                        klcc_logits, _ = self(idx[:, -klcc_window_size:], kv_cache=None)\n",
        "                        klcc_loss = F.kl_div(F.log_softmax(klcc_logits, dim=-1), F.softmax(all_logits[:, -klcc_window_size:].detach(), dim=-1), reduction='batchmean')\n",
        "                        # print(\"KLCC loss:\", klcc_loss.item())\n",
        "                        klcc_optimizer.zero_grad(set_to_none=True)\n",
        "                        klcc_loss.backward()\n",
        "                        klcc_optimizer.step()\n",
        "                    less_kv_cache = []\n",
        "                    for k, v in kv_cache:\n",
        "                        less_k = k[:, :, -klcc_window_size:, :] if k is not None else None\n",
        "                        less_v = v[:, :, -klcc_window_size:, :] if v is not None else None\n",
        "                        less_kv_cache.append((less_k, less_v))\n",
        "                    kv_cache = less_kv_cache\n",
        "                    self.eval()\n",
        "                    all_logits = None\n",
        "                # append sampled index to the running sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "                # since we have kv cache, only need to pass new token\n",
        "                idx_context = idx_next\n",
        "                        \n",
        "            return idx\n",
        "        else:\n",
        "            raise NotImplementedError(\"generate without kv cache is not implemented\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6339072"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test forward pass\n",
        "config = TransformerConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    seq_len=seq_len,\n",
        "    embed_size=256,\n",
        "    head_num=4,\n",
        "    layer_num=6\n",
        ")\n",
        "m = TransformerLM(config)\n",
        "m.to(device)\n",
        "xb, yb = get_batch('train', 5, 1)\n",
        "logits, loss = m(xb, yb)\n",
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be9c68f0a11e40968f3cd9511d1c38d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/coder/Python_project/transformers_playground/.venv/lib/python3.12/site-packages/torch/_inductor/lowering.py:1917: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final loss: 1.0032691955566406 final val loss: 1.1773799061775208\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "train(model, optimizer, seq_len, batch_size, total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "# torch.save(model.state_dict(), 'models/TransformerLM.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'models/TransformerLM.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m model = TransformerLM(config)\n\u001b[32m      3\u001b[39m model = torch.compile(model)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/TransformerLM.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m model.to(device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Python_project/transformers_playground/.venv/lib/python3.12/site-packages/torch/serialization.py:1479\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1477\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1481\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1482\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1483\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1484\u001b[39m         orig_position = opened_file.tell()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Python_project/transformers_playground/.venv/lib/python3.12/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Python_project/transformers_playground/.venv/lib/python3.12/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models/TransformerLM.pt'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "model = TransformerLM(config)\n",
        "model = torch.compile(model)\n",
        "model.load_state_dict(torch.load('models/TransformerLM.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # calculate perplexity\n",
        "# ppl, loss = perplexity(model, seq_len, seq_len)\n",
        "# print(\"perplexity:\", ppl, \"loss:\", loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n",
            "You will never forgive me as a friend.\n",
            "\n",
            "That's not what I thought, or anything was burned with the bottom of the body.\n",
            "\n",
            "But I don't think you could come up with a weapon.\n",
            "\n",
            "I think you're really going to be able to keep up with you guys.\n",
            "\n",
            "That's why I want to do it.\n",
            "\n",
            "But what do you want to do with this?\n",
            "\n",
            "You won't get away from me.\n",
            "\n",
            "There's not much there.\n",
            "\n",
            "I can't care less about what you are to be doing.\n",
            "\n",
            "I want to be a little more cheating.\n",
            "\n",
            "I want to see the beach at me.\n",
            "\n",
            "I want to be a girl, too.\n",
            "\n",
            "I'm sure you'll get along well.\n",
            "\n",
            "So this isn't the time to be serious about what happens to the top of the game.\n",
            "\n",
            "The heart of the companion of the support department.\n",
            "\n",
            "The same as usual about the moment you send this world to the starting point of the first set,\n",
            "\n",
            "Shirase-chan and the others would be able to control the greater height and see how they have to be here as well.\n",
            "\n",
            "I thought I had a choice, so I should go home to the starting level.\n",
            "\n",
            "I'll take you to the extra first-years.\n",
            "\n",
            "There's no way \n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=1000, temperature=0.5, use_cache=True)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "asdlkajdlkas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[53, 72, 78,  1, 80, 66, 69, 69,  1, 71, 62, 79, 62, 75]])\n",
            "You will never get to see your face dear assessments.\n",
            "\n",
            "You are also the same as me.\n",
            "\n",
            "But you can't stay calm and study.\n",
            "\n",
            "You can go to bed all the time.\n",
            "\n",
            "That's why I said we could all be able to protect him.\n",
            "\n",
            "So I was thinking I would be the same as if I had some tea.\n",
            "\n",
            "So I thought he was so cool and was a better than he was born.\n",
            "\n",
            "I thought I saw her for a long time.\n",
            "\n",
            "I thought something was going on because I couldn't tell anyone.\n",
            "\n",
            "I mean, I was just thinking about what I was doing for a while.\n",
            "\n",
            "But I was worried about her father.\n",
            "\n",
            "I was sure you were thinking about that, I was thinking I wouldn't make you a proper look in your eyes.\n",
            "\n",
            "I wonder what I should do.\n",
            "\n",
            "I was wondering why I was so worried\n",
            "\n",
            "I was wondering why I was looking forward to seeing her again.\n",
            "\n",
            "She was so sad\n",
            "\n",
            "I wasn't planning to go home with you.\n",
            "\n",
            "I wasn't thinking about how I would get so happy.\n",
            "\n",
            "I was wondering what I was going to say about that.\n",
            "\n",
            "I was wondering why I was worried about you.\n",
            "\n",
            "But I was wondering if I were a little too happy.\n",
            "\n",
            "But I was worried about how I would like to see you again.\n",
            "\n",
            "But I was worried about that.\n",
            "\n",
            "But I wouldn't want you to say it.\n",
            "\n",
            "I wouldn't want you to say it.\n",
            "\n",
            "But I wouldn't want to go home.\n",
            "\n",
            "But I wouldn't wake you up.\n",
            "\n",
            "Because I wouldn't have to see you would say something like that.\n",
            "\n",
            "Because I wouldn't say that.\n",
            "\n",
            "But I wouldn't want you to say so much about you.\n",
            "\n",
            "Because I wouldn't think of anyone else as wearing me.\n",
            "\n",
            "Besides I wouldn't think of how I wouldn't say anything.\n",
            "\n",
            "Besides, I wouldn't tell you.\n",
            "\n",
            "Besides, I wouldn't have told you.\n",
            "\n",
            "I wouldn't wake you up.\n",
            "\n",
            "Besides, I wouldn't...\n",
            "\n",
            "Besides that I wouldn't...\n",
            "\n",
            "I wouldn't... be a little smart...\n",
            "\n",
            "I wouldn't... I... wouldn't... say...\n",
            "\n",
            "how I wouldn't...\n",
            "\n",
            "think I wouldn't... lose... if...\n",
            "\n",
            "I wouldn't... but...\n",
            "\n",
            "I wouldn't...\n",
            "\n",
            "I wouldn't... say it...\n",
            "\n",
            "I wouldn't...I wouldn't...\n",
            "\n",
            "but I wouldn't...\n",
            "\n",
            "have done anything...\n",
            "\n",
            "that... I...uru...um...um...um...um...um...um...u.u.u.u.u.u.u.u.u.u.u.um..um..u.u.u.u.u..um..u.u.u.u..um..u.u.u.u.um..um..u..u.u.u..um..u.u.u.u..um..u..um..u.u.u.under...um...um.ur..uma...u.u.t..u..um..u.u.u.u.um.u.u..um.u.u.um.u.u.u.um.u.u.um..u.u.u.u.um.u.u.u.um..u.u..um..u..u.u.u..uma..u.u.um.u.u.um.u.undo.u.u.um..u.um.u.um.u..um.u.u..um..u.u.um.u.u.um.u.u..u.um.u.um.u..u.um.u.u..uma.u.u..uma.u.u..um.u.uma..u.u.u..um.u.u.um..u.u.u.uma..u.u.um.u.u..um.u.u.um.u..uma.u.u.u.um.u.u.un.u.um.u.u.um.u.u.u.u.um.u..u..u.u..u.um.u.u..uma.u.u.um.u.u.u...u.um.u.u.u.um.u.u.u.uma..u.u.u..uma.u.u..u.uma.u.u.um.u.u.um.u.u.um..u.u..u.u.um.u.u..u.um..u.um.u.u.um.u.u..uma.u.un!u.uma.a.u.u.una.a.u.u..u.u..uma.u.u.u.uma.a.u.u.u.!!!!!!!!!!!!!!!!!!!!!!!!!.u!!!!!\n",
            "\n",
            "Sure..!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "\n",
            "I wouldn't...uma!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!ut!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!u!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!u!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!u!!!!u!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!u!!!!!u!u!!!!!!!!!!!!!!!!!!u!u!!!!!!!!!!!u!!!u!!!!!!!!!!!!!!u!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!!u!!!!!u!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!u!!!!u!u!!u!u!!u!!!!u!!u!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!u!!!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!u!!u!!!!!!!!!u!!!!!!!u!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!!!!!!!u!!!!!!u!!!!!!!u!u!!!!!!!!!!u!u!!u!!!!u!!!!!!!!!!!!!!!u!!!!!!!!!!!!!u!u!!u!!!!!!!!!!!!!!!!!u!!!!!!!!!!u!!!!!!u!!!u!!!!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!u!u!!!!!!!!u!!u!u!u!!!!!!u!u!u!!!!!!!!!!!!!!!u!!!!!!!!!!!!!!!!!!!!u!!u!!!!u!u!!!!!!!!!!!!!!u!u!um!!!u!!!u!u!!!!!!!u!!u!u!!u!!!u!u!!!!!!!!!!!u!!u!!!!!u!!!!!!!!!!u!!u!!!u!u!!!u!!u!!!u!!u!u!u-u!!!!!!!!u!u!!u!!!u!!u!u!u!u!!u!u!u!u!!!!!!u!!u!u!u!!!!!!!!!!!!!u!!u!u!!!u!u!u!u!!u!!!u!!u!u!u!!!!!!!!!!u!!!u!u!!!!!!u!!!!!!u!u!!!!!!!!!!!!u!!!u!u!!u!u!!u!!!!!!!!u!u!!!!!!!u!!!u!!!!u!!!!u!!u!!!!u!!!!!!!!!u!!!u!!!u!!!!!u!!!u!!u!u!u!!u!!!!!!!!u!!!!!!!!!!!!!u!u!!!!u!!!!!!!!!!!!!!!!!u!u!!u!u!u!!u!!!u!ua!!!u!!u!!u!!!!!u!!!u!!!u!!!!u!!!u!!!!!!!!u!!u!u!!u!u!u!!!!!!!!!u!u!u!!u!!!!!!u!!u!u!u!!ub!u!u!!!!ua!!u!u!!!u!u!!!!!!u!u!!!!!u!!!!u!!u!!ut!!!!!!u!u!!!!!!!!!!u!!!!!u!!u!!!ua!!!!!!!!u!!!!!u!!!!u!!u!!u!!!u!u!u!!!u!!!!!!u!!u!!u!!u!!ua!!!u!u!u!!u!!!!!!!u!!!u!u!!!!u!u!u!!u!u!!u!!u!!u!u!u!u!!!!!!!!!u!!u!!!u!!!u!!um!!!!!u!u!!!u!!!u!!!u!!!!!!u!!u!u!!!u!u!!!u!u!!u!!!!u!u!!u!!u!u!u!!u!!!u!!!!!!u!u!u!u!!!u!!!!u!!!!u!!u!u!!u!!u!!u!ua!!!!u!u!u!!!!!u!!!!u!!!!!!!u!!!u!!!!u!!u!!!!!!u!!!!u!!!!u!!!!!!!!u!u!u!!u!!u!!u!!!u!uba!u!u!u!u!!!u!u!ube!!uato!u!!!u!u!!u!!!u!u!u!u!u!!u!!!!u!!!!!!!!u!u!!!!!!u!u!!!!u!!u!!u!u!u!!!!!!!!!!u!!!!!!!u!!u!u!!!!!!!!!!u!u!!!u!!!!u!!!!ub!!!!!!!!!!!!!u!!u!!!!u!!u!!!!!!!!u!!!ut!!u!!u!u!!!!ua!!!!u!!u!!!uta!!!!!!!!!u!u!!!!!!!!!!!!!u!u!u!!!!u!u!u!ua!!ua!!!!!!!!!!u!u!!!!u!!!!!!!!u!u!!!u!uba!u!!!!u!!!!u!u!ua!uta!!!!u!!!!!!!u!!!u!u!u!!!!!u!!!u!!u!u!!!u!!!!ua!u!!u!!u!!!!!!u!!u!u!u!u!!!!u!!!!!!u!!!!!!!!u!u!ubat!!!u!u!!!!!!u!!!!!!!!!!u!!!!!!!!!!!!!!!!!!u!!!!!!!ua!!!!u!!!!!u!!u!!!!!!!!!!ua!!u!ua!!u!!!utaru!uta!u!!!!!!!!!!!!u!u!!u!ua!!!!!!u!!!!!!!!!u!!!!u!!!!u!u!u!!!!ua!!!!!uai!!!!!!!u!!!!u!u!!u-!ua!!ua!!!!!!uatu!!!!!u!!!u!!!!!!!!!!!!!!u!u!!u!!!!!!!!!!!!!u!u!!u!!!!u!ue!!!!!ua!utou!u!uatu!!!u!ua!umubata!u!!!ua!uaa!u!u!u!!!!!u!u!ua!!!!ua!!ua!!!ua!!!!!ua!!u!!ue!!!!!u!!!!u!!!ua!u!!u!!uawa!!!!!uwaa!u!u!!ua!!!!!!!!!!!!!uaa!!uaa!ubu!uama!!!!!!!um!!!!!!u!u!!!!!!!!u!!!!!u!u!ute!ube!!!!!!!!utabu!!uat!!ua!uamu!utabu!!utt!uam!!u!u!!!!!!u!!!uata!!u!u!!!!!!!!u!!u!!u!!!!!!!!ua!!!!!u!!!uatabu!uau!!!!!!u!!!u!!u!u!utawaru!!!ua!uamuee!!!!!!!u!!u!u!!!!!!!!!!u!!!!u!!!!!!!!!!uaame!!!uaa!ue!u!!ue!!!!!!!uau!!!!!ua!uawe!!!uat!uata!ute!!uamueee!u!!!uatuamu!!u!!!u!u!!!!!uaaame!!!!!uamueee!uee!!!!!ue!utee!u!u!uamu!uateea!!!u-!uate!uru!!!u!u!!uameee!uame!!ume!!u!!!!uat!!!!!uaame!!ue!!!!!!!!uamu!u!!uatamuatataa!!uaatate!!ue!um!ueee!!u!u!!!!uatamataete!u!!!!!!!uae!ubatabe!!uee!!!!!!uatata!u!!!!!ue!!!!!!!uattem!u!!!uamueeee!!!!!uaeeee!u!uee!!!!u!uma!ueeue!!uamaam!!!!!uatata!!!!!!!!ueee!!!!!uau!uee!u!uee!!!!uameeeam!!!!uatatatae!uattatatte!!!u!ueee!u!ute!!!!!!!!!uamueeete!!!uamabe!uamaa!!!!uame!!!!ame!!ueee!!u!!!uamueeee!!!!!!!!!!!!ue!!u!!!!!!!uatat!!!ueee!uateee!!!ume!!!ueee!ute!!!u!ueeeeeeeeeexe!!!!!!!!!!!!!!uee!ue!!uee!u!ue!uamueee!!!!!!!!!!ueeee!!!ue!!!!!!!!!!!!!uamutteeetezuttta!ueeeee!!!ue!!!!!!!!!!!!!!!!!!!!!uamu!!!!!!!!!!!!!!ue!u!!!!!!u!!!!!!!!!uateeexteexe!!!!!!!!!!!!!!!Exexee!!!uamxutte!!!!!!!uatam!u!!!!!!!!!!!!!!!!!uamataattattttatatttattt!!!!!!!!!!!!!!!!!!!!!!!!!!!uataax!!Exeamtattattexatae!!!!!!!!!!!!E!!!uttttttuttex!uamutattttttuttttt!!!!ueeeee!!uxateextattt!!!!!!!!umueextext!!!!!!Eameexe!!!!!!!!!!!!!!!!!Exteexteexteettatttte!Extexteame!!!!!!!!!Exame!!!!!!!!!Ex!!!!!Extexttatttuattttttuteeextttex!!!!!Extexttatuxxtutt!Ext!ExtamExtettu!!Extextam!@@@ExteExtatie!Exx!!!Extexttutttexxtexmtat!Extutt!Ex!Extextutamx!!Extextuexxxtt!Extexmutexxtu!Exteextute!Exttttuxxtute!@@@@@@@@@@@@tmx!!!!!Extexxtutexxtatix!@@@@ttutttttutextexxuxxatie!Extitutxxte!Extamttututte!!Extextit!!Extxtttuttttttuxxtttttxtutttx!Exttttttuttimxx!!!!!!!Extextuxtxmtttutuxtttuxttttxtuxx!Extetuxtextutitxxtte!@@@xtxttttxxtutttttixxtutexxtitxtuttim!@!!@@@@@@@@@@@@@@ttuttixtxtuttxxtuxtttitilxtitxtExtexttextiltimiexxtux!!!Extxtuxxtttuxxt!Extxtitxxtt!Ext!Extutixtxttxxttxttuxtttuxxtttxtuttxtxxtiti!xmx!uttxtuxtu!@xtxtt!!!!!!Extxxxtttutttuxxtxtttttxtxxtuxxttxtuxxttttttuxxtx!xtttExtxttttltxtExtuxmxttutimx!!!!xtxtuxxtExtxtttuxttt!xttitxxt!!!!!@@xtuxxx!x!!!!!!ExttxxtttuxtExttuxtttuxxtExtuxxtttxtuxttuxttttuxtttttuxtttttttxxx!!xttxtttxxtxtttuxxtxxtrx!xtxtuxxttrx!xtuxxtttttuxtttuxxtttxtuxxttixxxttuxxttttuxttxtuxttttuxtxt@xttxtttuxxtxttxxtuxtttuxxtilx!xtxtuxxttuxxmxtrxtuxxxtixtttuxxtttxx!xltxxttttuxxtxxttxx!!!x!!xxxtxxxx!xxtxxxtttixxxttxxtuxttuxxtxtuxxtxxxtttuxxttuxxttxtuxxtuxxxtuxxxttlxxtxtExttix!xxttilxtixxxtxtuxtilxxttuxxtx!xxxtxx\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "idx = encode(\"You will never\")\n",
        "print(torch.tensor([idx]))\n",
        "print(decode(model.generate(idx=torch.tensor([idx], dtype=torch.long).to(device), max_new_tokens=10000, temperature=0.5, use_cache=True, use_klcc=True, klcc_cutoff=128, klcc_window_size=32, klcc_steps=15)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
